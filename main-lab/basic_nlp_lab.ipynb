{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/immanuel4082/DSA_application/blob/main/main-lab/basic_nlp_lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PzahbHOKuBfL"
      },
      "source": [
        "# BASIC NLP Lab\n",
        "In this section, we shall create more emphasis on what has already been covered in the pre-lab.\n",
        "\n",
        "## Objectives\n",
        "* Understand sentence segmentation.\n",
        "* Understand various ways of getting word embeddings.\n",
        "* Understand Part of Speech (POS) tagging.\n",
        "* Understand Named Entity Recognition (NER)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCtSOH6ev4Y-"
      },
      "source": [
        "Run this notebook at your own pace. Most of the code is already here, together with explanations. However, feel free to go back to the pre-lab to cross-reference related sections.\n",
        "Furthermore, there are a few places marked with `# Your code here` that require you to write code for the cells to run. Typically an archetype of this code can be found in the corresponding pre-lab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8F3QKXjst05",
        "outputId": "77518c6a-9292-489f-ee40-d2b1ecb06090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.73-py2.py3-none-any.whl (8.7 kB)\n",
            "Collecting textsearch>=0.0.21 (from contractions)\n",
            "  Downloading textsearch-0.0.24-py2.py3-none-any.whl (7.6 kB)\n",
            "Collecting anyascii (from textsearch>=0.0.21->contractions)\n",
            "  Downloading anyascii-0.3.2-py3-none-any.whl (289 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyahocorasick (from textsearch>=0.0.21->contractions)\n",
            "  Downloading pyahocorasick-2.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.7/110.7 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.2 contractions-0.1.73 pyahocorasick-2.1.0 textsearch-0.0.24\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2024.5.15)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.4)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n"
          ]
        }
      ],
      "source": [
        "# Install packages\n",
        "! pip install contractions\n",
        "! pip install nltk\n",
        "! pip install gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1LiRB-cqtiUv"
      },
      "outputs": [],
      "source": [
        "# Load dependencies\n",
        "import numpy as np\n",
        "import re\n",
        "import requests\n",
        "import nltk\n",
        "nltk.download('wordnet', quiet=True)\n",
        "nltk.download('stopwords', quiet=True)\n",
        "nltk.download('omw-1.4', quiet=True)\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
        "from nltk.corpus import gutenberg, stopwords, wordnet\n",
        "from nltk import FreqDist, word_tokenize, pos_tag\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder\n",
        "from nltk.util import trigrams\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from collections import Counter\n",
        "import spacy\n",
        "from spacy.tokenizer import Tokenizer\n",
        "import math\n",
        "import contractions\n",
        "from itertools import islice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0AM1sWrG2fH2",
        "outputId": "abdc0452-455d-4ec3-e9df-4241499c1d7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
          ]
        }
      ],
      "source": [
        "# Init spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "print(nlp.pipe_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU8fnzilst0-"
      },
      "source": [
        "### Text cleaning\n",
        "\n",
        "**Optional**. This is a standalone introductory section. You can skip it if you're confident in your understanding of text cleaning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbkimkuvst1A"
      },
      "source": [
        "Text cleaning is a fundamental pre-step before running machine learning models on text. This is simply because as humans we communicate differently compared to what an algorithm deems essential for working with text. For example, words like `a, the` etc might not be as important for the algorithm. Let's explore this below.\n",
        "\n",
        "Let us first work with the reuters dataset which contains short articles from Reuters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LHm4bFCOst1B",
        "outputId": "d34c7495-7229-43f8-b54c-a8449ae551bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package reuters to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "nltk.download('reuters')\n",
        "from nltk.corpus import reuters\n",
        "categories = ['nickel', 'gold', 'silver', 'tea', 'barley', 'fuel', 'crude', 'gas', 'heat']\n",
        "fields_for_categories = []\n",
        "docs_per_category = 10\n",
        "for c in categories:\n",
        "  fields_for_categories.append(reuters.fileids(c)[0:docs_per_category])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOxbzrGkst1D",
        "outputId": "1256d4c8-5897-4da9-a4a1-51037431c74e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WESTERN MINING TO OPEN NEW GOLD MINE IN AUSTRALIA '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "reuters_sample = ' '.join(reuters.words(fields_for_categories[1]))\n",
        "reuters_sample[0:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CIfUeZVBst1E"
      },
      "outputs": [],
      "source": [
        "def tokenize_text(text):\n",
        "    pattern = r\"[a-zA-Z]+(?:'[a-z]+)?\"  # Regex pattern to match words, including those with apostrophes\n",
        "    text_tokens = nltk.regexp_tokenize(text, pattern)  # Tokenize using the regex pattern\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text_tokens = [lemmatizer.lemmatize(word.lower().strip()) for word in text_tokens]  # Convert tokens to lowercase, lemmatize, remove extra whitespace\n",
        "    return text_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIjVTxvYst1F",
        "outputId": "b2b07b48-f434-49b8-91ef-0f5ab090bbe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('the', 80),\n",
              " ('to', 40),\n",
              " ('of', 40),\n",
              " ('a', 37),\n",
              " ('and', 31),\n",
              " ('gold', 29),\n",
              " ('said', 27),\n",
              " ('in', 22),\n",
              " ('at', 20),\n",
              " ('s', 16),\n",
              " ('it', 15),\n",
              " ('with', 13),\n",
              " ('warrant', 13),\n",
              " ('is', 11),\n",
              " ('dlrs', 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "r_sample_tokens = tokenize_text(reuters_sample) # tokenize the text\n",
        "r_sample_freqdist =FreqDist(r_sample_tokens) # Get frequency distributions\n",
        "r_sample_freqdist.most_common(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t4lvgYrVst1G"
      },
      "source": [
        "To automatically define stop-words, we can assume that these are words that occur very frequently.\n",
        "If we have a small corpus that is limited to a specific domain, like all articles about \"gold\" in the reuters dataset used above, then this is not a great strategy.\n",
        "We see that the word \"gold\" is very frequent (since it's the topic of this dataset selection), however it's not a stopword.\n",
        "\n",
        "Clearly we don't want to remove words like \"gold\" since this is the category of the article.\n",
        "\n",
        "Let's then load a set of stopwords that is computed on \"all\" of english language."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffY5O1MMst1H",
        "outputId": "8c277cba-10e9-44ee-83b2-1e8faaaa6a05",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "example_sent = \"\"\"This is a sample sentence,\n",
        "                  showing off the stop words filtration.\"\"\"\n",
        "\n",
        "\n",
        "def filter_stop_words(sent, return_as_list=False):\n",
        "  sent_tokenized = word_tokenize(sent)\n",
        "  ret = [w for w in sent_tokenized if not w.lower() in stop_words]\n",
        "  if return_as_list:\n",
        "    return ret\n",
        "  else:\n",
        "    return ' '.join(ret)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqqgWCR8st1d",
        "outputId": "bebef3ee-0210-431f-ad56-1c4e5dfb19f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text: WESTERN MINING TO OPEN NEW GOLD MINE IN AUSTRALIA \n",
            "Filtered text: WESTERN MINING OPEN NEW GOLD MINE AUSTRALIA\n"
          ]
        }
      ],
      "source": [
        "print(f'Original text: {reuters_sample[0:50]}')\n",
        "print(f'Filtered text: {filter_stop_words(reuters_sample[0:50])}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDu9X5Wxst1d"
      },
      "source": [
        "Let's now define a more generic clean text function.\n",
        "What else should a text be cleaned for? For example, 'constitutes' can be changed to 'constitute', since the exact form of a verb is not as useful for semantic text processing tasks.\n",
        "\n",
        "Consider the following text:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAD_Y66tst1d"
      },
      "outputs": [],
      "source": [
        "example_text = \"\"\"Lorem Ipsum is simply dummy text of the printing and typesetting industry. \\\n",
        "Lorem Ipsum constitutes the industry's standard dummy text ever since the 1500s, when an unknown \\\n",
        "printer took a galley of type and scrambled it to make a type specimen book. It has survived not \\\n",
        "only five centuries, but also the leap into electronic typesetting, remaining essentially unchanged. \\\n",
        "It was popularised in the 1960s with the release of Letraset sheets containing Lorem Ipsum passages, \\\n",
        "and more recently with desktop publishing software like Aldus PageMaker including versions of Lorem Ipsum.\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzqkGowtst1e"
      },
      "outputs": [],
      "source": [
        "def clean_text1(text):\n",
        "  text = contractions.fix(text) # Fix contractions\n",
        "  text = text.lower() # lowercase the text\n",
        "  text = text.replace('\\n', ' ') # replace new line characters with whitespace\n",
        "  text = re.sub(r\"[^\\w\\s']\", ' ', text) # Remove non-word characters, except apostroophes - to handle possessives correctly e.g \"John's\"\n",
        "  text = text.strip() # Remove extra whitespace\n",
        "\n",
        "  ## -- Tokenize, lemmatize, remove stopwords -- ##\n",
        "  doc = nlp(text)\n",
        "  tokens = [token.lemma_.strip() for token in doc if not token.is_stop and not token.is_punct] # Lemmatize and exclude stopwords\n",
        "  tokens = [token for token in tokens if token != ''] # Exclude empty strings\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aP01tkOUst1e",
        "outputId": "ec9cc8c9-510d-4bc0-fd51-dece786f9a11",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['lorem', 'ipsum', 'simply', 'dummy', 'text', 'printing', 'typeset', 'industry', 'lorem', 'ipsum', 'constitute', 'industry', 'standard', 'dummy', 'text', '1500s', 'unknown', 'printer', 'take', 'galley', 'type', 'scramble', 'type', 'speciman', 'book', 'survive', 'century', 'leap', 'electronic', 'typesetting', 'remain', 'essentially', 'unchanged', 'popularise', '1960', 'release', 'letraset', 'sheet', 'contain', 'lorem', 'ipsum', 'passage', 'recently', 'desktop', 'publishing', 'software', 'like', 'aldus', 'pagemaker', 'include', 'version', 'lorem', 'ipsum']\n"
          ]
        }
      ],
      "source": [
        "print(clean_text1(example_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyQ3ploUst1e"
      },
      "source": [
        "### N-grams\n",
        "\n",
        "**Optional** This is a standalone section. You can skip it if you're confident in your understanding of n-grams."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJvb8oqEst1e"
      },
      "source": [
        "N-grams are continuous sequences of n words from a given text. Types of n-grams include:\n",
        "* Unigrams - 1 word e.g ('God'). This can also be viewed as frequency distribution.\n",
        "* Bigrams - 2 words e.g ('Lord', 'God')\n",
        "* Trigrams - 3 words e.g ('Lord', 'God', 'said')\n",
        "\n",
        "Consider the below sentence and try to identify the top 3 n-grams by frequency, for n = 2,3.\n",
        "Try to do this manually, i.e. in your head or using pen and paper. You just have to write the pairs of occurences for words (or triplets for 3-grams etc) and count their frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uq7Mow9Mst1e"
      },
      "outputs": [],
      "source": [
        "example_sentence = '''A cat jumped over the bed.\n",
        "The cat jumped over the bed quickly.\n",
        "The cat jumped over the fence.\n",
        "The dog chased the cat.\n",
        "The dog chased a squirrel.\n",
        "The man chased the cat.'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHTUbh-tst1e"
      },
      "source": [
        "Now implement code to compute ngrams programmatically - you can look at the pre-lab notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KtptY7azst1f"
      },
      "outputs": [],
      "source": [
        "# ngrams code\n",
        "\n",
        "# Your code here\n",
        "\n",
        "# def ngrams(tokens, n):\n",
        "  # TODO\n",
        "\n",
        "# def ngram_freq(text, n):\n",
        "  # TODO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXSa0c0Gst1f",
        "outputId": "adac8158-1597-4fee-a171-a9182675ee5b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('cat', 'jump'), 3),\n",
              " (('jump', 'bed'), 2),\n",
              " (('dog', 'chase'), 2),\n",
              " (('chase', 'cat'), 2),\n",
              " (('bed', 'cat'), 1),\n",
              " (('bed', 'quickly'), 1),\n",
              " (('quickly', 'cat'), 1),\n",
              " (('jump', 'fence'), 1),\n",
              " (('fence', 'dog'), 1),\n",
              " (('cat', 'dog'), 1),\n",
              " (('chase', 'squirrel'), 1),\n",
              " (('squirrel', 'man'), 1),\n",
              " (('man', 'chase'), 1)]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngram_freq(filter_stop_words(example_sentence),2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA3zBhRBst1f",
        "outputId": "de50e1de-877d-4d8c-e9f7-068205375cf7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('cat', 'jump', 'bed'), 2),\n",
              " (('jump', 'bed', 'cat'), 1),\n",
              " (('bed', 'cat', 'jump'), 1),\n",
              " (('jump', 'bed', 'quickly'), 1),\n",
              " (('bed', 'quickly', 'cat'), 1),\n",
              " (('quickly', 'cat', 'jump'), 1),\n",
              " (('cat', 'jump', 'fence'), 1),\n",
              " (('jump', 'fence', 'dog'), 1),\n",
              " (('fence', 'dog', 'chase'), 1),\n",
              " (('dog', 'chase', 'cat'), 1),\n",
              " (('chase', 'cat', 'dog'), 1),\n",
              " (('cat', 'dog', 'chase'), 1),\n",
              " (('dog', 'chase', 'squirrel'), 1),\n",
              " (('chase', 'squirrel', 'man'), 1),\n",
              " (('squirrel', 'man', 'chase'), 1),\n",
              " (('man', 'chase', 'cat'), 1)]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngram_freq(filter_stop_words(example_sentence),3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XmA4Abust1f",
        "outputId": "733afd4c-dd30-4472-b636-1b5acc72dbd4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(('Cape', 'Spencer'), 6),\n",
              " (('000', 'ton'), 6),\n",
              " (('`', '`'), 5),\n",
              " (('GOLD', 'WARRANTS'), 4),\n",
              " (('April', '30'), 4),\n",
              " (('100', 'gramme'), 4),\n",
              " (('gold', 'price'), 4),\n",
              " (('ton', 'gold'), 4),\n",
              " (('gold', 'bear'), 4),\n",
              " (('bear', 'deposit'), 4)]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ngram_freq(filter_stop_words(reuters_sample), 2)[0:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q4OzoFP3st1f"
      },
      "source": [
        "The above hopefully makes some sense and it's what one should expect (this is a limited domain with a simple stop word filtration, so the results won't be perfect!)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRWYyDcrst1f"
      },
      "source": [
        "## Sentence Segmentation\n",
        "Sentence segmentation invlolves the identification of of sentence boundaries between words, and dividing the text into individual sentences based on the established boundaries.\n",
        "\n",
        "This can be done by using the following methods:\n",
        "* A vivid indication of the sentence end such as '?' or '!'\n",
        "* Using an unclear indication such as the period (.) - This may have several other uses such as abbreviations. For example, when abbrevition Mr.\n",
        "\n",
        "One way to think about sentence segmentation is that it is tokenization at the sentence level, where the tokens are sentences as opposed to words like we saw earlier during the pre-lab. The machine can learn to know the difference between a sentence end and an abbreviation.\n",
        "\n",
        "Sentence segmentation can be important in certain tasks such as machine translation and text summarization.\n",
        "\n",
        "The two popular approaches to sentence segmentation are rule-based and machine learning-based sentence segmentation. In this lab, we shall look at rule-based sentence segmentation using the default rules. Using spaCy, one could add a custom rule to spaCy's nlp pipeline.\n",
        "\n",
        "To demonstrate the above, we return to the Gutenberg corpus, familiar from the pre-lab notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39vBjVOL5BO-",
        "outputId": "ced67831-1282-42cd-bb20-df5b903044a0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Great Gatsby:\n",
            "I    In my younger and more vulnerable years my father gave me some advice  that I’ve been turning over in my mind ever since.    “Whenever you feel like criticizing anyone,” he told me, “just  remember that all the people in this world haven’t had the advantages  that you’ve had.”    He didn’t say any more, but we’ve always been unusually communicative  in a reserved way, and I understood that he meant a great deal more  than that. In consequence, I’m inclined to reserve all judgements, a  habi\n",
            "====================================================================================================\n",
            "Adventures of Huckleberry Finn:\n",
            "CHAPTER I.      You don’t know about me without you have read a book by the name of The  Adventures of Tom Sawyer; but that ain’t no matter. That book was made  by Mr. Mark Twain, and he told the truth, mainly. There was things  which he stretched, but mainly he told the truth. That is nothing. I  never seen anybody but lied one time or another, without it was Aunt  Polly, or the widow, or maybe Mary. Aunt Polly—Tom’s Aunt Polly, she  is—and Mary, and the Widow Douglas is all told about in that \n",
            "====================================================================================================\n",
            "The Adventures of Sherlock Holmes:\n",
            "A SCANDAL IN BOHEMIA      I.    To Sherlock Holmes she is always _the_ woman. I have seldom heard him  mention her under any other name. In his eyes she eclipses and  predominates the whole of her sex. It was not that he felt any emotion  akin to love for Irene Adler. All emotions, and that one particularly,  were abhorrent to his cold, precise but admirably balanced mind. He  was, I take it, the most perfect reasoning and observing machine that  the world has seen, but as a lover he would have \n",
            "====================================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Run without making changes\n",
        "def request_gutenberg(url):\n",
        "\n",
        "  # Make a request to the url\n",
        "  response = requests.get(url)\n",
        "\n",
        "  # check if the request was successful\n",
        "  if response.status_code == 200:\n",
        "    book = response.text\n",
        "\n",
        "  else:\n",
        "    print(f\"Failed to retrieve the text version. Status code: {response.status_code}\")\n",
        "\n",
        "  # remove unwanted new line and tab characters from the text, replacing with whitespace\n",
        "  unwanted_chars = [\"\\n\", \"\\r\", \"\\d\", \"\\t\"]\n",
        "  for char in unwanted_chars:\n",
        "      book = book.replace(char, \" \")\n",
        "\n",
        "  return book\n",
        "\n",
        "# URLs of the books to be used in this lab\n",
        "g_gatsby_url = \"https://www.gutenberg.org/cache/epub/64317/pg64317.txt\"\n",
        "huckleberry_finn_url = \"https://www.gutenberg.org/cache/epub/76/pg76.txt\"\n",
        "sherlock_holmes_url = \"https://www.gutenberg.org/files/1661/1661-0.txt\"\n",
        "\n",
        "# Make requests for each book\n",
        "g_gatsby = request_gutenberg(g_gatsby_url)[1494:277912] # Remove introduction and footnotes\n",
        "h_berry = request_gutenberg(huckleberry_finn_url)[9528:-18862]\n",
        "s_holmes = request_gutenberg(sherlock_holmes_url)[1508:-18859]\n",
        "\n",
        "books = {\n",
        "    \"The Great Gatsby\": g_gatsby,\n",
        "    \"Adventures of Huckleberry Finn\": h_berry,\n",
        "    \"The Adventures of Sherlock Holmes\": s_holmes\n",
        "    }\n",
        "\n",
        "# Preview\n",
        "for key, val in books.items():\n",
        "  print(f\"{key}:\")\n",
        "  print(val[:500])\n",
        "  print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "01eWw8raKFlB",
        "outputId": "23f8de1a-10e1-4cc6-d6a1-05ec3403eac8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'A SCANDAL IN BOHEMIA      I.    To Sherlock Holmes she is always _the_ woman. I have seldom heard him  mention her under any other name. In his eyes she eclipses and  predominates the whole of her sex. It was not that he felt any emotion  akin to love for Irene Adler. All emotions, and that one particularly,  were abhorrent to his cold, precise but admirably balanced mind. He  was, I take it, the most perfect reasoning and observing machine that  the world has seen, but as a lover he would have '"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def fix_encoding(text):\n",
        "    # Encode the incorrectly decoded text back to bytes\n",
        "    bytes_text = text.encode('latin1')\n",
        "    # Decode the bytes using the correct encoding (UTF-8)\n",
        "    corrected_text = bytes_text.decode('utf-8')\n",
        "    return corrected_text\n",
        "\n",
        "# Fix encoding of sherlock holmes\n",
        "s_holmes = fix_encoding(s_holmes)\n",
        "s_holmes[:500]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jVfHAqeB5L4Z"
      },
      "outputs": [],
      "source": [
        "# Get the end of the first chapter for both the Adventures of Sherlock Holmes and Adventures of Huckleberry Finn\n",
        "s_holmes_chap_1_end = s_holmes.index('II')\n",
        "h_berry_chap_1_end = h_berry.index('CHAPTER II')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "293WJf084k7r"
      },
      "source": [
        "### Rule-based Sentence segmentation\n",
        "In the code cells below, we shall segment sentences using nltk and spacy, spaCy's pre-trained models and etymological rules accurately identify sentence boundaries by using cues such as punctuation, capitalization, and other language-specific indicators.. How many sentences do we arrive at using this method?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS9tmhnf4jYd",
        "outputId": "2b03ca7b-d74b-4803-af34-62431ae4ea00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using NLTK:\n",
            "['You don’t know about me without you have read a book by the name of The  Adventures of Tom Sawyer; but that ain’t no matter.', 'That book was made  by Mr. Mark Twain, and he told the truth, mainly.', 'There was things  which he stretched, but mainly he told the truth.', 'That is nothing.', 'I  never seen anybody but lied one time or another, without it was Aunt  Polly, or the widow, or maybe Mary.', 'Aunt Polly—Tom’s Aunt Polly, she  is—and Mary, and the Widow Douglas is all told about in that book,  which is mostly a true book, with some stretchers, as I said before.', 'Now the way that the book winds up is this: Tom and me found the money  that the robbers hid in the cave, and it made us rich.', 'We got six  thousand dollars apiece—all gold.', 'It was an awful sight of money when  it was piled up.', 'Well, Judge Thatcher he took it and put it out at  interest, and it fetched us a dollar a day apiece all the year  round—more than a body could tell what to do with.', 'The Widow Douglas  she took me for her son, and allowed she would sivilize me; but it was  rough living in the house all the time, considering how dismal regular  and decent the widow was in all her ways; and so when I couldn’t stand  it no longer I lit out.', 'I got into my old rags and my sugar-hogshead  again, and was free and satisfied.', 'But Tom Sawyer he hunted me up and  said he was going to start a band of robbers, and I might join if I  would go back to the widow and be respectable.', 'So I went back.', 'The widow she cried over me, and called me a poor lost lamb, and she  called me a lot of other names, too, but she never meant no harm by it.']\n",
            "Number of sentences: 67\n",
            "\n",
            "Using Spacy:\n",
            "['You don’t know about me without you have read a book by the name of The  Adventures of Tom Sawyer; but that ain’t no matter.', 'That book was made  by Mr. Mark Twain, and he told the truth, mainly.', 'There was things  which he stretched, but mainly he told the truth.', 'That is nothing.', 'I  never seen anybody but lied one time or another, without it was Aunt  Polly, or the widow, or maybe Mary.', 'Aunt Polly—Tom’s Aunt Polly, she  is—and Mary, and the Widow Douglas is all told about in that book,  which is mostly a true book, with some stretchers, as I said before.    ', 'Now the way that the book winds up is this: Tom and me found the money  that the robbers hid in the cave, and it made us rich.', 'We got six  thousand dollars apiece—all gold.', 'It was an awful sight of money when  it was piled up.', 'Well, Judge Thatcher he took it and put it out at  interest, and it fetched us a dollar a day apiece all the year  round—more than a body could tell what to do with.', 'The Widow Douglas  she took me for her son, and allowed she would sivilize me; but it was  rough living in the house all the time, considering how dismal regular  and decent the widow was in all her ways; and so when I couldn’t stand  it no longer I lit out.', 'I got into my old rags and my sugar-hogshead  again, and was free and satisfied.', 'But Tom Sawyer he hunted me up and  said he was going to start a band of robbers, and I might join if I  would go back to the widow and be respectable.', 'So I went back.    ', 'The widow she cried over me, and called me a poor lost lamb, and she  called me a lot of other names, too, but she never meant no harm by it.  ']\n",
            "Number of sentences: 68\n"
          ]
        }
      ],
      "source": [
        "# using the first chapter of 'Adventures of Huckleberry Finn'\n",
        "h_berry_chap_1 = h_berry[16:h_berry_chap_1_end]\n",
        "\n",
        "# Using NLTK\n",
        "h_berry_sents_nltk = nltk.sent_tokenize(h_berry_chap_1)\n",
        "print(\"Using NLTK:\")\n",
        "print(h_berry_sents_nltk[:15])\n",
        "print(f\"Number of sentences: {len(h_berry_sents_nltk)}\")\n",
        "\n",
        "# Using spacy\n",
        "doc = nlp(h_berry_chap_1)\n",
        "\n",
        "h_berry_sents_spacy = [sent.text for sent in doc.sents]\n",
        "print(\"\\nUsing Spacy:\")\n",
        "print(h_berry_sents_spacy[:15])\n",
        "print(f\"Number of sentences: {len(h_berry_sents_spacy)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMzz0Wmt8__v"
      },
      "outputs": [],
      "source": [
        "# Get the first chapter of The Adventures of Sherlock Holmes and perform the sentence segmentation\n",
        "s_holmes_chap_1 = s_holmes[32:s_holmes_chap_1_end]\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVLtyWH3Ejm0"
      },
      "source": [
        "## Word Embeddings\n",
        "The discussion on word embeddings began with an exploration of Bag of Words (BoW) techniques like CountVectorizer and Term Frequency-Inverse Document Frequency (TF-IDF) in the pre-lab. Now, we delve into other methodologies for creating word embeddings.\n",
        "\n",
        "### Word2Vec\n",
        "Word2Vec, devised by Google researchers, introduces a neural approach to generating word embeddings. This model processes extensive text corpora and produces high-quality word vectors. It boasts the capability to analyze word contexts, thereby capturing semantic relationships as it maps words to high-dimensional vectors.\n",
        "\n",
        "#### Continuous Bag of Words (CBOW)\n",
        "CBOW, an unsupervised learning method, aims to predict a target word by considering its context—surrounding words within a specified window. It predicts the central word within the window and represents embeddings in a continuous vector space.\n",
        "\n",
        "In contrast to BoW, which disregards word context and thus fails to capture complete text meaning, CBOW's contextual awareness enhances its ability to capture textual semantics.\n",
        "\n",
        "#### Skip-Gram\n",
        "The Skip-Gram model seeks distributed word representations within a continuous vector space. Its objective is to predict context words (those adjacent to a target word) given the target word itself. This differs from CBOW, which predicts the target word from its surrounding context. Research suggests that Skip-Gram yields embeddings with richer semantic content compared to other methods.\n",
        "\n",
        "The choice between CBOW and Skip-Gram models hinges on data characteristics and task objectives. CBOW is favored with limited training data, prioritizing syntactic nuances. Conversely, Skip-Gram excels in capturing semantic associations and effectively representing infrequent words.\n",
        "\n",
        "The decision to train Word2Vec models using sentences or tokens depends on desired granularity in word embeddings and text data structure. Using entire sentences focuses on contextual information within sentences, beneficial for tasks like sentiment analysis. Employing individual tokens considers broader semantic relationships across the corpus, ideal for tasks like semantic similarity.\n",
        "\n",
        "Given the goal of understanding corpora broadly, using word tokens is preferred. The text preprocessing steps from the pre-lab will be utilized for this purpose.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kuoyMZtkMuXx"
      },
      "outputs": [],
      "source": [
        "# Load dependencies\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "import warnings\n",
        "\n",
        "# Disable warnings\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbodzuJWst1h"
      },
      "source": [
        "**Attention!!** For the following to run, you need to have run the `clean_text1` function in the \"Text Cleaning\" section from before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAGfDo-cjS0_",
        "outputId": "a22dfe39-f11b-467a-8269-0e3ca0c1aaa9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of distinct tokens: 4505\n"
          ]
        }
      ],
      "source": [
        "# Clean the text of the Great Gatsby\n",
        "gatsby_tokens = clean_text1(g_gatsby)\n",
        "gatsby_tokens = [token for token in gatsby_tokens if token != ''] # Exclude empty strings\n",
        "\n",
        "# Get the set of items\n",
        "n_gatsby_tokens = len(list(set(gatsby_tokens)))\n",
        "print(f\"Number of distinct tokens: {n_gatsby_tokens}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y9uMzrMWiOzv"
      },
      "outputs": [],
      "source": [
        "# Clean the text of The Adventures of Huckleberry Finn, getting the tokens and the number of distinct tokens\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1M7dqbW30MiY"
      },
      "outputs": [],
      "source": [
        "import multiprocessing\n",
        "\n",
        "# Count the number of cores in the cpu\n",
        "cores = multiprocessing.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQTCkZgthac9",
        "outputId": "ad9310bb-7b4f-4222-f27d-cf7871151bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CBOW Vector representation of gatsby: [-8.86559725e-01 -1.81378528e-01  4.39616174e-01  4.64231253e-01\n",
            "  2.05618832e-02 -5.57845533e-01 -5.56949377e-01  4.45696414e-01\n",
            "  5.03326833e-01 -1.13711345e+00  9.85719636e-02  3.37011695e-01\n",
            "  2.40804311e-02  6.06875420e-01  6.55139387e-02 -1.01007462e-01\n",
            " -3.10799092e-01  6.86958015e-01 -1.73614338e-01 -6.03697658e-01\n",
            "  7.09214330e-01  6.79432452e-02  9.65071499e-01  2.13001981e-01\n",
            "  8.58468711e-01 -2.65913308e-01 -8.63000825e-02  5.98906279e-02\n",
            " -8.99318159e-01  1.71200007e-01 -1.76569656e-01 -2.75519639e-01\n",
            "  8.16894054e-01 -4.45926994e-01  2.40044102e-01  1.61812589e-01\n",
            "  3.16141057e-04  6.72519729e-02 -8.06340426e-02 -1.27146160e-02\n",
            "  6.94722533e-01  6.19589031e-01 -3.11790198e-01 -3.15368891e-01\n",
            "  5.91712177e-01  1.18288195e+00 -7.41057158e-01  5.85344613e-01\n",
            "  8.42276037e-01  1.87176481e-01 -3.61720979e-01  3.71268749e-01\n",
            " -4.38868970e-01 -2.42873579e-02  2.52481788e-01  9.66386646e-02\n",
            " -2.50279129e-01 -2.17346281e-01 -3.55394334e-01  9.85514522e-02\n",
            " -6.61420524e-02  1.00306249e+00 -7.07500502e-02 -7.54283011e-01\n",
            "  3.59563291e-01  6.00495934e-01 -5.24900444e-02  4.31463540e-01\n",
            "  1.89254850e-01  1.24238586e+00 -2.74479464e-02  8.24032962e-01\n",
            " -2.08198190e-01 -2.04830635e-02  7.25702167e-01  2.77937979e-01\n",
            "  6.90065995e-02  4.25375104e-02 -1.24553695e-01 -2.07226306e-01\n",
            " -4.74621534e-01 -2.35069897e-02  2.23893985e-01  2.24414349e-01\n",
            " -6.88857615e-01 -1.69822145e-02  8.91294599e-01 -6.74529731e-01\n",
            " -4.33352679e-01  1.55040026e-01 -5.03177941e-01 -2.92092383e-01\n",
            " -1.12130806e-01  5.93895875e-02  8.27635944e-01  4.28757370e-01\n",
            " -5.18016458e-01 -9.40014124e-01 -6.90982401e-01  1.17055416e-01]\n"
          ]
        }
      ],
      "source": [
        "# CBOW model of the great gatsby text\n",
        "cbow_gatsby_model = Word2Vec(sentences=[gatsby_tokens],\n",
        "                             vector_size=100,  # Dimensionality of the word vectors\n",
        "                             window=5,         # Maximum distance between the current and predicted word within a sentence\n",
        "                             sg=0,             # CBOW model (0 for CBOW, 1 for Skip-Gram)\n",
        "                             min_count=10,      # Ignores all words with a total frequency lower than this\n",
        "                             workers=cores-1)       # cpu cores\n",
        "\n",
        "# Training\n",
        "cbow_gatsby_model.train([gatsby_tokens], total_examples=1, epochs=100)\n",
        "\n",
        "# Vector representation of gatsby\n",
        "word = 'gatsby'\n",
        "gatsby_vector_rep = cbow_gatsby_model.wv[word]\n",
        "print(f\"CBOW Vector representation of {word}: {gatsby_vector_rep}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8KI0AGKUZ_kK",
        "outputId": "499b0626-7674-4e42-959a-b07347328bba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipgram Vector representation of gatsby: \n",
            "[-0.18024732 -0.09232956  0.14114104  0.12256143 -0.02509932 -0.306543\n",
            " -0.22930494  0.24378636 -0.02201081 -0.22165959 -0.12634744 -0.06986495\n",
            " -0.16867855  0.09658261  0.32023928 -0.05351266  0.19858286  0.02122142\n",
            "  0.15911448 -0.2352864   0.12479225  0.00833586  0.28793105 -0.16111344\n",
            "  0.01476592 -0.0874582  -0.16370517 -0.14192711 -0.50962186  0.02396614\n",
            "  0.23980975 -0.03289191  0.04989801 -0.12883507 -0.20222813  0.33914214\n",
            "  0.07537403 -0.03964567  0.04666974  0.02001024  0.08658332  0.06286446\n",
            " -0.0383154  -0.08729084  0.0425876   0.12443601 -0.03918268  0.14614365\n",
            "  0.2214018  -0.05582196 -0.15995441  0.30738533 -0.04310428  0.01073627\n",
            " -0.14284793  0.19741325 -0.03511769 -0.12847136 -0.17367467  0.07212719\n",
            "  0.12195329  0.02406472 -0.13553993 -0.14818038 -0.06976158  0.3482297\n",
            " -0.06981976  0.24920073  0.02648384  0.2728288  -0.14204346 -0.12543984\n",
            " -0.11373128 -0.12506995  0.22557789  0.21130554 -0.26010925 -0.10203975\n",
            " -0.03343182 -0.05961495  0.06290708 -0.07642674 -0.16245997  0.21059988\n",
            " -0.21339901  0.12576988  0.23127721 -0.17548628  0.1087124   0.1505443\n",
            " -0.17865051 -0.00185846  0.19498274 -0.00293331  0.46262857  0.21790738\n",
            " -0.09064026 -0.26215246  0.07254191  0.03670812]\n"
          ]
        }
      ],
      "source": [
        "# Skipgram model of the Great Gatsby text\n",
        "skipgram_gatsby_model = Word2Vec(sentences=[gatsby_tokens],\n",
        "                          vector_size=100,  # Dimensionality of the word vectors\n",
        "                          window=5,         # Maximum distance between the current and predicted word within a sentence\n",
        "                          sg=1,             # Skip-Gram model (1 for Skip-Gram, 0 for CBOW)\n",
        "                          min_count=10,      # Ignores all words with a total frequency lower than this\n",
        "                          workers=cores-1)       # cpu cores\n",
        "\n",
        "# Training\n",
        "skipgram_gatsby_model.train([gatsby_tokens], total_examples=1, epochs=100)\n",
        "\n",
        "# Vector representation of gatsby\n",
        "word = 'gatsby'\n",
        "gatsby_vector_rep = skipgram_gatsby_model.wv[word]\n",
        "print(f\"Skipgram Vector representation of {word}: \\n{gatsby_vector_rep}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Gn-FIbciZHM"
      },
      "outputs": [],
      "source": [
        "# Create the Skipgram model of The Adventures of Huckleberry Finn\n",
        "\n",
        "# Vector representation of huck\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJBCSt3w7uaP"
      },
      "source": [
        "#### Exploring the model (Optional)\n",
        "\n",
        "In the code cells, we shall explore the model to perform some simple character analysis of the books The Great Gatsby and Advenures of Huckleberry Finn, that you can confirm later on after the lab as your homework."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mw9xK-Fj7zYp",
        "outputId": "76a820ba-d035-48d0-ac63-6f246c7fca86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Character relationships based on cosine similarity:\n",
            "Similarity between gatsby and daisy: 0.3974\n",
            "Similarity between gatsby and tom: 0.3467\n",
            "Similarity between daisy and tom: 0.5306\n"
          ]
        }
      ],
      "source": [
        "# Investigating the love triangle of the great gatsby\n",
        "# Investigate the relationships between the key characters\n",
        "gatsby_relationships = {\n",
        "    ('gatsby', 'daisy'): skipgram_gatsby_model.wv.similarity('gatsby', 'daisy'),\n",
        "    ('gatsby', 'tom'): skipgram_gatsby_model.wv.similarity('gatsby', 'tom'),\n",
        "    ('daisy', 'tom'): skipgram_gatsby_model.wv.similarity('daisy', 'tom'),\n",
        "}\n",
        "\n",
        "print(\"Character relationships based on cosine similarity:\")\n",
        "for (char1, char2), similarity in gatsby_relationships.items():\n",
        "    print(f\"Similarity between {char1} and {char2}: {similarity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "NUPuJoUPU6ft",
        "outputId": "25bce599-1b33-4380-b42f-caed15c050d9"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtEAAAIjCAYAAADFk0cVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8fJSN1AAAACXBIWXMAAA9hAAAPYQGoP6dpAABmtElEQVR4nO3deZzNdf//8eeZMYvBWDJmLIMsWcdyEd8hIWO/LJE9TImEECoKQyqUq4tEXZWlQrqsqSSTDCpb9mRfUhhLg8EwZnn//vCbcznNnGM+zD6P++02t8t5f96fz+f1eTmXnj7e53NsxhgjAAAAAKnmltkFAAAAANkNIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaACQdOXJELVq0UMGCBWWz2bRy5co0OW6TJk1UvXr1NDkW0s6ECRNks9l08eLFdD9XkyZN1KRJk7vOi4iIkM1mU0REhH0sNDRUZcuWTbfaANw7QjSQw2zfvl1DhgxRtWrVlC9fPpUuXVpdu3bV4cOHk81t0qSJbDabbDab3Nzc5Ovrq0qVKql3794KDw9P9TlDQ0Ptx7HZbPL19VXNmjX1r3/9S7Gxscnm7969W08++aQCAwPl5eWlIkWKKCQkRPPmzVNCQkKy+ZcvX5a3t7dsNpsOHDhgrSGp1LdvX+3bt09vvPGGPvvsM9WtW9fl/OjoaE2cOFE1a9ZU/vz5lTdvXlWvXl0vv/yyzpw5ky41ZrQ333wzzf4ykVp3vo/+/jNw4MAMrQUAXMmT2QUASFtTp07VTz/9pC5duqhGjRqKjIzUe++9p3/84x/asmVLsruipUqV0uTJkyVJ169f19GjR7V8+XItWLBAXbt21YIFC+Th4XHX83p5eenjjz+WdDv0Llu2TKNGjdL27du1ePFi+7yPP/5YAwcOlL+/v3r37q2KFSvq6tWrWrdunfr166ezZ8/qlVdecTj2kiVLZLPZFBAQoIULF+r111+/3zY5uHHjhjZv3qxXX31VQ4YMuev848ePKyQkRKdOnVKXLl00YMAAeXp6au/evZozZ45WrFiR4l9asps333xTTzzxhDp27Jih523evLn69OmTbPyhhx7K0Dqygo8++kiJiYmZXQaAFBCigRxmxIgRWrRokTw9Pe1j3bp1U1BQkKZMmaIFCxY4zC9YsKCefPJJh7EpU6Zo6NChmj17tsqWLaupU6fe9bx58uRxOM6gQYNUv359ffHFF3rnnXdUokQJbdmyRQMHDlRwcLBWr16tAgUK2OcPHz5cv/zyi3799ddkx16wYIHatGmjMmXKaNGiRWkeoi9cuCBJKlSo0F3nxsfHq1OnTjp37pwiIiL0yCOPOGx/4403UtWvtBQfH6/ExESH3/Os6ubNm/L09JSbm/N/CH3ooYeSvSdzq9T8BRZA5mA5B5DDNGjQIFmYqlixoqpVq5bqpRDu7u569913VbVqVb333nu6cuWK5Trc3Nzs60BPnjwpSZo4caJsNpsWLlzoEKCT1K1bV6GhoQ5jp06d0qZNm9S9e3d1795dJ06c0M8//5zqOnbt2qXWrVvL19dX+fPnV7NmzbRlyxb79gkTJqhMmTKSpBdffFE2m83lGtRly5Zpz549evXVV5MFaEny9fXVG2+8kWz8t99+U9OmTeXj46OSJUvqrbfecth+69YtjR8/XnXq1FHBggWVL18+NWrUSOvXr3eYd/LkSdlsNk2bNk3Tp09X+fLl5eXlpd9++y3Vx5CkxMREzZgxQ0FBQfL29pafn59atWqlX375RdLtZRXXr1/XJ598Yl9OcefvzenTp/X000/L399fXl5eqlatmubOnetwjqQ1vosXL9bYsWNVsmRJ+fj4KDo62ml/UytprfnevXvVuHFj+fj4qEKFClq6dKkkacOGDapfv77y5s2rSpUq6fvvv0/xOBcvXlTXrl3l6+urBx54QMOGDdPNmzeTzVuwYIHq1KmjvHnzqkiRIurevbv++OOPZPM+/PBDlS9fXnnz5lW9evW0adOmFM/7559/qmPHjsqXL5+KFSumF154IcWlT39fE33n73/Suby8vPTwww9r+/btyfZfsmSJqlatKm9vb1WvXl0rVqxIcZ314sWLVadOHRUoUEC+vr4KCgrSjBkzUqwdwG3ciQZyAWOMzp07p2rVqqV6H3d3d/Xo0UPjxo3Tjz/+qLZt21o+77FjxyRJDzzwgGJiYrRu3To9+uijKl26dKqP8fnnnytfvnz65z//qbx586p8+fJauHChGjRocNd99+/fr0aNGsnX11cvvfSSPDw89J///EdNmjSxh6xOnTqpUKFCeuGFF9SjRw+1adNG+fPnd3rMVatWSZJ69+6d6mu4dOmSWrVqpU6dOqlr165aunSpXn75ZQUFBal169aSbq+x/vjjj9WjRw/1799fV69e1Zw5c9SyZUtt27ZNtWrVcjjmvHnzdPPmTQ0YMMC+rtzKMfr166f58+erdevWeuaZZxQfH69NmzZpy5Ytqlu3rj777DM988wzqlevngYMGCBJKl++vCTp3Llz+r//+z/ZbDYNGTJEfn5++vbbb9WvXz9FR0dr+PDhDrVOmjRJnp6eGjVqlGJjY+96x/zmzZspfuDP19fXYd9Lly7pn//8p7p3764uXbro/fffV/fu3bVw4UINHz5cAwcOVM+ePfX222/riSee0B9//JHsL29du3ZV2bJlNXnyZG3ZskXvvvuuLl26pE8//dQ+54033tC4cePUtWtXPfPMM7pw4YJmzpypRx99VLt27bL/C8acOXP07LPPqkGDBho+fLiOHz+u9u3bq0iRIgoMDLQf78aNG2rWrJlOnTqloUOHqkSJEvrss8/0ww8/uOzLnRYtWqSrV6/q2Weflc1m01tvvaVOnTrp+PHj9rvX33zzjf1foSZPnqxLly6pX79+KlmypMOxwsPD1aNHDzVr1sz+rygHDhzQTz/9pGHDhqW6JiDXMQByvM8++8xIMnPmzHEYb9y4salWrZrT/VasWGEkmRkzZrg8ft++fU2+fPnMhQsXzIULF8zRo0fNm2++aWw2m6lRo4Yxxpg9e/YYSWbYsGGWag8KCjK9evWyv37llVdM0aJFTVxc3F337dixo/H09DTHjh2zj505c8YUKFDAPProo/axEydOGEnm7bffvusxa9eubQoWLJjq+hs3bmwkmU8//dQ+FhsbawICAkznzp3tY/Hx8SY2NtZh30uXLhl/f3/z9NNPJ6vV19fXnD9/3mF+ao/xww8/GElm6NChyepNTEy0/zpfvnymb9++yeb069fPFC9e3Fy8eNFhvHv37qZgwYImJibGGGPM+vXrjSRTrlw5+9jdSHL68/nnn9vnJfV10aJF9rGDBw8aScbNzc1s2bLFPv7dd98ZSWbevHn2sbCwMCPJtG/f3uH8gwYNMpLMnj17jDHGnDx50ri7u5s33njDYd6+fftMnjx57OO3bt0yxYoVM7Vq1XL4Pfjwww+NJNO4cWP72PTp040k89///tc+dv36dVOhQgUjyaxfv94+3rdvX1OmTBn766Tf/wceeMBERUXZx7/88ksjyXz11Vf2saCgIFOqVClz9epV+1hERISR5HDMYcOGGV9fXxMfH28ApB7LOYAc7uDBgxo8eLCCg4PVt29fS/sm3ZG9evXqXedev35dfn5+8vPzU4UKFfTKK68oODhYK1askCT7P+GntIzDmb1792rfvn3q0aOHfaxHjx66ePGivvvuO5f7JiQkaO3aterYsaPKlStnHy9evLh69uypH3/88Z6WFURHR1u6Bul2H+9c4+vp6al69erp+PHj9jF3d3f7XdbExERFRUUpPj5edevW1c6dO5Mds3PnzvLz83MYS+0xli1bJpvNprCwsGTHtdlsLq/FGKNly5apXbt2Msbo4sWL9p+WLVvqypUryert27ev8ubN6/K4d+rQoYPCw8OT/TRt2tRhXv78+dW9e3f760qVKqlQoUKqUqWK6tevbx9P+vWd/U4yePBgh9fPP/+8JGn16tWSpOXLlysxMVFdu3Z1uNaAgABVrFjRvlTml19+0fnz5zVw4ECHu+WhoaEqWLCgwzlWr16t4sWL64knnrCP+fj42O/4p0a3bt1UuHBh++tGjRo5XOOZM2e0b98+9enTx+FfVho3bqygoCCHYxUqVEjXr1+39EQeACznAHK0yMhItW3bVgULFtTSpUvl7u5uaf9r165JSl3w9fb21ldffSXp9pM6HnzwQZUqVcq+3dfXV1LqAnmSBQsWKF++fCpXrpyOHj1qP0/ZsmW1cOFCl0tMLly4oJiYGFWqVCnZtipVqigxMVF//PGHpSUuSdeRUhhzpVSpUsnCaeHChbV3716HsU8++UT/+te/dPDgQcXFxdnHH3zwwWTHTGkstcc4duyYSpQooSJFili6Dul2Xy9fvqwPP/xQH374YYpzzp8/n6panSlVqpRCQkJSNe/vfS1YsKDD0omkMen28o+/q1ixosPr8uXLy83Nzb6O/8iRIzLGJJuXJGnpxO+//57i8Tw8PBz+Epc0t0KFCslqT+m96szfl0QlBeqka0yqp0KFCsn2rVChgsNfdAYNGqT//ve/at26tUqWLKkWLVqoa9euatWqVarrAXIjQjSQQ125ckWtW7fW5cuXtWnTJpUoUcLyMZKelJHSf4j/zt3d3WXwqVChgvLkyaN9+/al6tzGGH3++ee6fv26qlatmmz7+fPnde3aNZfrl9ND5cqVtWvXLv3xxx/Jwpozzv7yYoyx/3rBggUKDQ1Vx44d9eKLL6pYsWJyd3fX5MmT7WvL75TSnV2rx7gXSY9be/LJJ53+y0aNGjXuWmtacNbX1PTbmb8H28TERNlsNn377bcpHjej339J7uca/65YsWLavXu3vvvuO3377bf69ttvNW/ePPXp00effPLJ/ZYK5FiEaCAHunnzptq1a6fDhw/r+++/TzGE3k1CQoIWLVokHx+fFJ9CYZWPj48ee+wx/fDDD6kKoBs2bNCff/6p1157TVWqVHHYdunSJQ0YMEArV650+ig0Pz8/+fj46NChQ8m2HTx4UG5ubqkOwXdq166dPv/8cy1YsEBjxoyxvL8zS5cuVbly5bR8+XKHIJfSkov7PUb58uX13XffKSoqyuXd6JSWdvj5+alAgQJKSEhI1d3irO7IkSMOd8qPHj2qxMRE+9MrypcvL2OMHnzwQZfPqU56wsuRI0f02GOP2cfj4uJ04sQJ1axZ02Hur7/+KmOMQ49Teq/eq6R6kv4F504pjXl6eqpdu3Zq166dEhMTNWjQIP3nP//RuHHjUvWXaCA3Yk00kMMkJCSoW7du2rx5s5YsWaLg4OB7OsbQoUN14MABDR061L4U436FhYXJGKPevXvbl4rcaceOHfY7X0lLOV588UU98cQTDj/9+/dXxYoVtXDhQqfncnd3V4sWLfTll1/a/2leuv1kiUWLFumRRx65p+t64oknFBQUpDfeeEObN29Otv3q1at69dVXLR836c7inXcSt27dmuI57vcYnTt3ljFGEydOTHaMO/fNly+fLl++nOwcnTt31rJly1J8pnfSM7ezi1mzZjm8njlzpiTZn5rSqVMnubu7a+LEicnu8hpj9Ndff0m6/XhGPz8/ffDBB7p165Z9zvz585P1sE2bNjpz5oz9cXySFBMT43R5zL0oUaKEqlevrk8//dTh/2sbNmxI9q9BSdeQxM3Nzf6vCSk9dg/AbdyJBnKYkSNHatWqVWrXrp2ioqKSfbnK3+/cXrlyxT4nJibG/o2Fx44dU/fu3TVp0qQ0q61BgwaaNWuWBg0apMqVKzt8Y2FERIRWrVql119/XbGxsVq2bJmaN28ub2/vFI/Vvn17zZgxQ+fPn1exYsVSnPP6668rPDxcjzzyiAYNGqQ8efLoP//5j2JjY5M9pzm1PDw8tHz5coWEhOjRRx9V165d1bBhQ3l4eGj//v1atGiRChcunOKzol355z//qeXLl+vxxx9X27ZtdeLECX3wwQeqWrVqin/huJ9jNG3aVL1799a7776rI0eOqFWrVkpMTNSmTZvUtGlT+7c21qlTR99//739y3IefPBB1a9fX1OmTNH69etVv3599e/fX1WrVlVUVJR27typ77//XlFRUZau/e8OHz6c7H0rSf7+/mrevPl9HfvvTpw4ofbt26tVq1bavHmzFixYoJ49e9rvHJcvX16vv/66xowZo5MnT6pjx44qUKCATpw4oRUrVmjAgAEaNWqUPDw89Prrr+vZZ5/VY489pm7duunEiROaN29esjXR/fv313vvvac+ffpox44dKl68uD777DP5+Pik6bW9+eab6tChgxo2bKinnnpKly5d0nvvvafq1as7vB+eeeYZRUVF6bHHHlOpUqX0+++/a+bMmapVq1ayfwUCcIeMfyAIgPSU9OgvZz+u5ubPn99UrFjRPPnkk2bt2rWpPmfSI+5Sa8eOHaZnz56mRIkSxsPDwxQuXNg0a9bMfPLJJyYhIcEsW7YsxUfy3SnpUV13e/zezp07TcuWLU3+/PmNj4+Padq0qfn5558d5lh5xF2SS5cumfHjx5ugoCDj4+NjvL29TfXq1c2YMWPM2bNn7fOcPUbw748uS0xMNG+++aYpU6aM8fLyMrVr1zZff/2100ecpVRrao9hzO3H4b399tumcuXKxtPT0/j5+ZnWrVubHTt22OccPHjQPProoyZv3rxGksPj7s6dO2cGDx5sAgMDjYeHhwkICDDNmjUzH374oX1O0iPulixZkuq+unrv3vmYOGd9LVOmjGnbtm2Kxx08eLD9ddIj7n777TfzxBNPmAIFCpjChQubIUOGmBs3biTbf9myZeaRRx4x+fLlM/ny5TOVK1c2gwcPNocOHXKYN3v2bPPggw8aLy8vU7duXbNx40bTuHFjh9qNMeb333837du3Nz4+PqZo0aJm2LBhZs2aNal+xF1Kv/+STFhYmMPY4sWLTeXKlY2Xl5epXr26WbVqlencubOpXLmyfc7SpUtNixYtTLFixYynp6cpXbq0efbZZx3exwCSsxlzD59CAAAA2VKtWrXk5+fHI+2A+8SaaAAAcqC4uDjFx8c7jEVERGjPnj1q0qRJ5hQF5CDciQYAIAc6efKkQkJC9OSTT6pEiRI6ePCgPvjgAxUsWFC//vqrHnjggcwuEcjW+GAhAAA5UOHChVWnTh19/PHHunDhgvLly6e2bdtqypQpBGggDXAnGgAAALAoW62J3rhxo9q1a6cSJUrIZrNp5cqVd90nIiJC//jHP+Tl5aUKFSpo/vz56V4nAAAAcrZsFaKvX7+umjVrJns4vjMnTpxQ27Zt1bRpU+3evVvDhw/XM888o++++y6dKwUAAEBOlm2Xc9hsNq1YsUIdO3Z0Oufll1/WN9984/CtWt27d9fly5e1Zs2aVJ0nMTFRZ86cUYECBVL8ClwAAABkLmOMrl69qhIlSsjNLWPuEefoDxZu3rxZISEhDmMtW7bU8OHDne4TGxvr8DWnp0+fVtWqVdOrRAAAAKSRP/74Q6VKlcqQc+XoEB0ZGSl/f3+HMX9/f0VHR+vGjRvKmzdvsn0mT56siRMnJhv/+OOP0/wrWQEAAHD/YmJi9Mwzz6hAgQIZds4cHaLvxZgxYzRixAj76+joaAUGBqpjx47y9fXNxMrST1xcnMLDw9W8eXN5eHhkdjlZCr1xjf44R29coz/O0Rvn6I1rubk/0dHReuaZZzJ06W2ODtEBAQE6d+6cw9i5c+fk6+ub4l1oSfLy8pKXl1eycQ8Pjxz/hswN13iv6I1r9Mc5euMa/XGO3jhHb1zLjf3JjOvNVk/nsCo4OFjr1q1zGAsPD1dwcHAmVQQAAICcIFuF6GvXrmn37t3avXu3pNuPsNu9e7dOnTol6fZSjD59+tjnDxw4UMePH9dLL72kgwcPavbs2frvf/+rF154ITPKBwAAQA6RrUL0L7/8otq1a6t27dqSpBEjRqh27doaP368JOns2bP2QC1JDz74oL755huFh4erZs2a+te//qWPP/5YLVu2zJT6AQAAkDNkqzXRTZo0kavHWqf0bYRNmjTRrl270rEqAAAA5DbZ6k40AAAAkBUQogEAAACLCNEA7surr76qkSNHpmpuRESEbDabLl++nL5FAQCQzgjRADJMgwYNdPbsWRUsWDCzSwEA4L5kqw8WAsjePD09FRAQkNllAABw37gTDSDVrl+/rj59+ih//vwqXry4/v3vfzts/+yzz1S3bl0VKFBAAQEB6tmzp86fP2/f/vflHL///rvatWunwoULK1++fKpWrZpWr14tY4wqVKigadOmORx/9+7dstlsOnr0aLpfKwAArhCiAaTaiy++qA0bNujLL7/U2rVrtWHDBh0/fty+PS4uTpMmTdKePXu0cuVKnTx5UqGhoU6PN3jwYMXGxmrjxo3at2+fpk6dqvz588tms+npp5/WvHnzHObPmzdPjz76qCpUqJBelwgAQKqwnANAqly7dk1z5szRggUL1KxZM0nS3LlzVbp0afucp59+2v7rcuXK6d1339XDDz+sa9euKX/+/MmOeerUKXXu3FlBQUH2fZKEhoZq/Pjx2rZtm+rVq6e4uDgtWrQo2d1pAAAyA3eiAbiUkCBFREjvvXdMt27dUt269e3bihQpopIlS9pf79ixQ+3atVPp0qVVoEABNW7cWJIcvkn0TkOHDtXrr7+uhg0bKiwsTHv37rVvK1GihNq2bau5c+dKkr766ivFxsaqS5cu6XCVAABYQ4gG4NTy5VLZslLTptKYMbfHGjS4Pf53169fV8uWLeXr66uFCxdq+/btWrFihSTp1q1bKR7/mWee0fHjx9W7d2/t27dPdevW1cyZMx22L168WDdu3NC8efPUrVs3+fj4pPVlAgBgGSEaQIqWL5eeeEL688+kkfKSPBQZuVVPPHF7+6VLl3TmzBlJ0sGDB/XXX39pypQpatSokSpXruzwoUJnAgMDNXDgQC1fvlwjR47URx99ZN/Wpk0b5cuXT++//77WrFnjsFwEAIDMxJpoAMkkJEjDhknG3DmaX1I/SS/KmAc0aFAxPfzwGNlsNklS6dKl5enpqZkzZ2rgwIH69ddfNWnSJJfnGT58uFq3bq2HHnpIly5d0vr161WlShX7dnd3d4WGhmrMmDGqWLGigoOD0/xaAQC4F9yJBpDMpk133oG+09uSGklqp3PnQlSiREOVL19ekuTn56f58+dryZIlqlq1qqZMmXLXDwEmJCRo8ODBqlKlilq1aqWHHnpIs2fPdpjTr18/3bp1S0899VSaXBsAAGmBO9EAkjl71tmW/JI++/8/UpMmcWrTporatGkjSerRo4d69OjhsIe543Z2kyZNHF7fuf7ZmdOnT8vDw0N9+vSxcgkAAKQr7kQDSKZ48dTNS88vH4yNjdWff/6pCRMmqEuXLvL390+/kwEAYBEhGkAyjRpJpUpJ/3+5czI2mxQYKKXnEuXPP/9cZcqU0eXLl/XWW2+l34kAALgHhGgAybi7SzNm3P7134N00uvp02/PSy+hoaFKSEjQjh07HJ5FDQBAVkCIBpCiTp2kpUulv+fXUqVuj3fqlDl1AQCQFfDBQgBOdeokdehw+2kdZ8/eXivdqFH63oEGACA7IEQDcMndXWrSJLOrAAAga2E5BwAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLsl2InjVrlsqWLStvb2/Vr19f27Ztczl/+vTpqlSpkvLmzavAwEC98MILunnzZgZVCwAAgJwoW4XoL774QiNGjFBYWJh27typmjVrqmXLljp//nyK8xctWqTRo0crLCxMBw4c0Jw5c/TFF1/olVdeyeDKAQAAkJNkqxD9zjvvqH///nrqqadUtWpVffDBB/Lx8dHcuXNTnP/zzz+rYcOG6tmzp8qWLasWLVqoR48ed717DQAAALiSJ7MLSK1bt25px44dGjNmjH3Mzc1NISEh2rx5c4r7NGjQQAsWLNC2bdtUr149HT9+XKtXr1bv3r2dnic2NlaxsbH219HR0ZKkuLg4xcXFpdHVZC1J15VTr+9+0BvX6I9z9MY1+uMcvXGO3riWm/uTGddsM8aYDD/rPThz5oxKliypn3/+WcHBwfbxl156SRs2bNDWrVtT3O/dd9/VqFGjZIxRfHy8Bg4cqPfff9/peSZMmKCJEycmG1+0aJF8fHzu/0IAAACQpmJiYtSzZ09duXJFvr6+GXLObHMn+l5ERETozTff1OzZs1W/fn0dPXpUw4YN06RJkzRu3LgU9xkzZoxGjBhhfx0dHa3AwEC1aNEiw35TMlpcXJzCw8PVvHlzeXh4ZHY5WQq9cY3+OEdvXKM/ztEb5+iNa7m5P0krBzJStgnRRYsWlbu7u86dO+cwfu7cOQUEBKS4z7hx49S7d28988wzkqSgoCBdv35dAwYM0Kuvvio3t+RLwr28vOTl5ZVs3MPDI8e/IXPDNd4reuMa/XGO3rhGf5yjN87RG9dyY38y43qzzQcLPT09VadOHa1bt84+lpiYqHXr1jks77hTTExMsqDs7u4uScomq1gAAACQBWWbO9GSNGLECPXt21d169ZVvXr1NH36dF2/fl1PPfWUJKlPnz4qWbKkJk+eLElq166d3nnnHdWuXdu+nGPcuHFq166dPUwDAAAAVmWrEN2tWzdduHBB48ePV2RkpGrVqqU1a9bI399fknTq1CmHO89jx46VzWbT2LFjdfr0afn5+aldu3Z64403MusSAAAAkANkqxAtSUOGDNGQIUNS3BYREeHwOk+ePAoLC1NYWFgGVAYAAIDcItusiQYAAACyCkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgUbYL0bNmzVLZsmXl7e2t+vXra9u2bS7nX758WYMHD1bx4sXl5eWlhx56SKtXr86gagEAAJAT5cnsAqz44osvNGLECH3wwQeqX7++pk+frpYtW+rQoUMqVqxYsvm3bt1S8+bNVaxYMS1dulQlS5bU77//rkKFCmV88QAAAMgxslWIfuedd9S/f3899dRTkqQPPvhA33zzjebOnavRo0cnmz937lxFRUXp559/loeHhySpbNmyGVkyAAAAcqBsE6Jv3bqlHTt2aMyYMfYxNzc3hYSEaPPmzSnus2rVKgUHB2vw4MH68ssv5efnp549e+rll1+Wu7t7ivvExsYqNjbW/jo6OlqSFBcXp7i4uDS8oqwj6bpy6vXdD3rjGv1xjt64Rn+cozfO0RvXcnN/MuOabcYYk+FnvQdnzpxRyZIl9fPPPys4ONg+/tJLL2nDhg3aunVrsn0qV66skydPqlevXho0aJCOHj2qQYMGaejQoQoLC0vxPBMmTNDEiROTjS9atEg+Pj5pd0EAAABIEzExMerZs6euXLkiX1/fDDlntrkTfS8SExNVrFgxffjhh3J3d1edOnV0+vRpvf32205D9JgxYzRixAj76+joaAUGBqpFixYZ9puS0eLi4hQeHq7mzZvbl73gNnrjGv1xjt64Rn+cozfO0RvXcnN/klYOZKRsE6KLFi0qd3d3nTt3zmH83LlzCggISHGf4sWLy8PDw2HpRpUqVRQZGalbt27J09Mz2T5eXl7y8vJKNu7h4ZHj35C54RrvFb1xjf44R29coz/O0Rvn6I1rubE/mXG92eYRd56enqpTp47WrVtnH0tMTNS6desclnfcqWHDhjp69KgSExPtY4cPH1bx4sVTDNAAAABAamSbEC1JI0aM0EcffaRPPvlEBw4c0HPPPafr16/bn9bRp08fhw8ePvfcc4qKitKwYcN0+PBhffPNN3rzzTc1ePDgzLoEAAAA5ADZZjmHJHXr1k0XLlzQ+PHjFRkZqVq1amnNmjXy9/eXJJ06dUpubv/7e0FgYKC+++47vfDCC6pRo4ZKliypYcOG6eWXX86sSwAAAEAOkK1CtCQNGTJEQ4YMSXFbREREsrHg4GBt2bIlnasCAABAbpKtlnMAAAAAWQEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFiU7UL0rFmzVLZsWXl7e6t+/fratm1bqvZbvHixbDabOnbsmL4FAgAAIMfLViH6iy++0IgRIxQWFqadO3eqZs2aatmypc6fP+9yv5MnT2rUqFFq1KhRBlUKAACAnCxPZhdgxTvvvKP+/fvrqaeekiR98MEH+uabbzR37lyNHj06xX0SEhLUq1cvTZw4UZs2bdLly5ddniM2NlaxsbH219HR0ZKkuLg4xcXFpc2FZDFJ15VTr+9+0BvX6I9z9MY1+uMcvXGO3riWm/uTGddsM8aYDD/rPbh165Z8fHy0dOlShyUZffv21eXLl/Xll1+muF9YWJj27t2rFStWKDQ0VJcvX9bKlSudnmfChAmaOHFisvFFixbJx8fnfi8DAAAAaSwmJkY9e/bUlStX5OvrmyHnzDZ3oi9evKiEhAT5+/s7jPv7++vgwYMp7vPjjz9qzpw52r17d6rPM2bMGI0YMcL+Ojo6WoGBgWrRokWG/aZktLi4OIWHh6t58+by8PDI7HKyFHrjGv1xjt64Rn+cozfO0RvXcnN/klYOZKRsE6Ktunr1qnr37q2PPvpIRYsWTfV+Xl5e8vLySjbu4eGR49+QueEa7xW9cY3+OEdvXKM/ztEb5+iNa7mxP5lxvdkmRBctWlTu7u46d+6cw/i5c+cUEBCQbP6xY8d08uRJtWvXzj6WmJgoScqTJ48OHTqk8uXLp2/RAAAAyJGyzdM5PD09VadOHa1bt84+lpiYqHXr1ik4ODjZ/MqVK2vfvn3avXu3/ad9+/Zq2rSpdu/ercDAwIwsHwAAADlItrkTLUkjRoxQ3759VbduXdWrV0/Tp0/X9evX7U/r6NOnj0qWLKnJkyfL29tb1atXd9i/UKFCkpRsHAAAALAiW4Xobt266cKFCxo/frwiIyNVq1YtrVmzxv5hw1OnTsnNLdvcXAcAAEA2la1CtCQNGTJEQ4YMSXFbRESEy33nz5+f9gUBAAAg1+G2LQAAAGARIRoAAACwyFKIvnHjhn788Uf99ttvybbdvHlTn376aZoVBgAAAGRVqQ7Rhw8fVpUqVfToo48qKChIjRs31tmzZ+3br1y5Yn9KBgAAAJCTpTpEv/zyy6pevbrOnz+vQ4cOqUCBAmrYsKFOnTqVnvUBAAAAWU6qQ/TPP/+syZMnq2jRoqpQoYK++uortWzZUo0aNdLx48fTs0YAAAAgS0l1iL5x44by5PnfE/FsNpvef/99tWvXTo0bN9bhw4fTpUAAAAAgq0n1c6IrV66sX375RVWqVHEYf++99yRJ7du3T9vKAAAAgCwq1XeiH3/8cX3++ecpbnvvvffUo0cPGWPSrDAAAAAgq0p1iB4zZoxWr17tdPvs2bOVmJiYJkUBAAAAWRlftgIAAABYRIgGAAAALCJEAwAAABYRogEAAACLLIfojRs3Kj4+Ptl4fHy8Nm7cmCZFAQAAAFmZ5RDdtGlTRUVFJRu/cuWKmjZtmiZFAQAAAFmZ5RBtjJHNZks2/tdffylfvnxpUhQAAACQlaX6Gws7deok6fbXfYeGhsrLy8u+LSEhQXv37lWDBg3SvkIAAAAgi0l1iC5YsKCk23eiCxQooLx589q3eXp66v/+7//Uv3//tK8QAAAAyGJSHaLnzZsnSSpbtqxGjRrF0g0AAADkWqkO0UnCwsLSow4AAAAg27D8wcJz586pd+/eKlGihPLkySN3d3eHHwAAACCns3wnOjQ0VKdOndK4ceNUvHjxFJ/UAQAAAORklkP0jz/+qE2bNqlWrVrpUA4AAACQ9VlezhEYGChjTHrUAgAAAGQLlkP09OnTNXr0aJ08eTIdygEAAACyPsvLObp166aYmBiVL19ePj4+8vDwcNie0leCAwAAADmJ5RA9ffr0dCgDAAAAyD4sh+i+ffumRx0AAABAtmF5TbQkHTt2TGPHjlWPHj10/vx5SdK3336r/fv3p2lxAAAAQFZkOURv2LBBQUFB2rp1q5YvX65r165Jkvbs2cO3GQIAACBXsByiR48erddff13h4eHy9PS0jz/22GPasmVLmhYHAAAAZEWWQ/S+ffv0+OOPJxsvVqyYLl68mCZFAQAAAFmZ5RBdqFAhnT17Ntn4rl27VLJkyTQpCgAAAMjKLIfo7t276+WXX1ZkZKRsNpsSExP1008/adSoUerTp0961AgAAABkKZZD9JtvvqnKlSsrMDBQ165dU9WqVfXoo4+qQYMGGjt2bHrUCAAAAGQplp8T7enpqY8++kjjxo3Tr7/+qmvXrql27dqqWLFietQHAAAAZDmWQ3SS0qVLq3Tp0mlZCwAAAJAtWA7RCQkJmj9/vtatW6fz588rMTHRYfsPP/yQZsUBAAAAWZHlED1s2DDNnz9fbdu2VfXq1WWz2dKjLgAAACDLshyiFy9erP/+979q06ZNetQDAAAAZHmWn87h6empChUqpEctAAAAQLZgOUSPHDlSM2bMkDEmPeq5q1mzZqls2bLy9vZW/fr1tW3bNqdzP/roIzVq1EiFCxdW4cKFFRIS4nI+AAAAkBqWl3P8+OOPWr9+vb799ltVq1ZNHh4eDtuXL1+eZsX93RdffKERI0bogw8+UP369TV9+nS1bNlShw4dUrFixZLNj4iIUI8ePdSgQQN5e3tr6tSpatGihfbv38+3KwIAAOCeWQ7RhQoV0uOPP54etdzVO++8o/79++upp56SJH3wwQf65ptvNHfuXI0ePTrZ/IULFzq8/vjjj7Vs2TKtW7eOb1cEAADAPbMcoufNm5ceddzVrVu3tGPHDo0ZM8Y+5ubmppCQEG3evDlVx4iJiVFcXJyKFCnidE5sbKxiY2Ptr6OjoyVJcXFxiouLu8fqs7ak68qp13c/6I1r9Mc5euMa/XGO3jhHb1zLzf3JjGu2mXtc3HzhwgUdOnRIklSpUiX5+fmlaWF/d+bMGZUsWVI///yzgoOD7eMvvfSSNmzYoK1bt971GIMGDdJ3332n/fv3y9vbO8U5EyZM0MSJE5ONL1q0SD4+Pvd+AQAAAEgXMTEx6tmzp65cuSJfX98MOaflO9HXr1/X888/r08//dT+RSvu7u7q06ePZs6cmWWD5pQpU7R48WJFREQ4DdCSNGbMGI0YMcL+Ojo6WoGBgWrRokWG/aZktLi4OIWHh6t58+bJ1rjndvTGNfrjHL1xjf44R2+cozeu5eb+JK0cyEiWQ/SIESO0YcMGffXVV2rYsKGk2x82HDp0qEaOHKn3338/zYuUpKJFi8rd3V3nzp1zGD937pwCAgJc7jtt2jRNmTJF33//vWrUqOFyrpeXl7y8vJKNe3h45Pg3ZG64xntFb1yjP87RG9foj3P0xjl641pu7E9mXK/lR9wtW7ZMc+bMUevWreXr6ytfX1+1adNGH330kZYuXZoeNUq6/XzqOnXqaN26dfaxxMRErVu3zmF5x9+99dZbmjRpktasWaO6deumW30AAADIPSzfiY6JiZG/v3+y8WLFiikmJiZNinJmxIgR6tu3r+rWrat69epp+vTpun79uv1pHX369FHJkiU1efJkSdLUqVM1fvx4LVq0SGXLllVkZKQkKX/+/MqfP3+61goAAICcy/Kd6ODgYIWFhenmzZv2sRs3bmjixIku7winhW7dumnatGkaP368atWqpd27d2vNmjX2UH/q1CmdPXvWPv/999/XrVu39MQTT6h48eL2n2nTpqVrnQAAAMjZLN+JnjFjhlq2bKlSpUqpZs2akqQ9e/bI29tb3333XZoX+HdDhgzRkCFDUtwWERHh8PrkyZPpXg8AAAByH8shunr16jpy5IgWLlyogwcPSpJ69OihXr16KW/evGleIAAAAJDVWA7RkuTj46P+/fundS0AAABAtnBPIfrQoUOaOXOmDhw4IEmqUqWKhgwZosqVK6dpcQAAAEBWdE+PuKtevbp27NihmjVrqmbNmtq5c6eCgoK0bNmy9KgRAAAAyFIs34l+6aWXNGbMGL322msO42FhYXrppZfUuXPnNCsOAAAAyIos34k+e/as+vTpk2z8ySefdHi8HAAAAJBTWQ7RTZo00aZNm5KN//jjj2rUqFGaFAUAAABkZZaXc7Rv314vv/yyduzYof/7v/+TJG3ZskVLlizRxIkTtWrVKoe5AAAAQE5jOUQPGjRIkjR79mzNnj07xW2SZLPZlJCQcJ/lAQAAAFmP5RCdmJiYHnUAAAAA2YblNdEAAABAbndPX7ayfft2rV+/XufPn092Z/qdd95Jk8IAAACArMpyiH7zzTc1duxYVapUSf7+/rLZbPZtd/4aAAAAyKksh+gZM2Zo7ty5Cg0NTYdyAAAAgKzP8ppoNzc3NWzYMD1qAQAAALIFyyH6hRde0KxZs9KjFgAAACBbsLycY9SoUWrbtq3Kly+vqlWrysPDw2H78uXL06w4AAAAICuyHKKHDh2q9evXq2nTpnrggQf4MCEAAAByHcsh+pNPPtGyZcvUtm3b9KgHAAAAyPIsr4kuUqSIypcvnx61AAAAANmC5RA9YcIEhYWFKSYmJj3qAQAAALI8y8s53n33XR07dkz+/v4qW7Zssg8W7ty5M82KAwAAALIiyyG6Y8eO6VAGAAAAkH1YDtFhYWHpUQcAAACQbVgO0Ul27NihAwcOSJKqVaum2rVrp1lRAAAAQFZmOUSfP39e3bt3V0REhAoVKiRJunz5spo2barFixfLz88vrWsEAAAAshTLT+d4/vnndfXqVe3fv19RUVGKiorSr7/+qujoaA0dOjQ9agQAAACyFMt3otesWaPvv/9eVapUsY9VrVpVs2bNUosWLdK0OAAAACArsnwnOjExMdlj7STJw8NDiYmJaVIUAAAAkJVZDtGPPfaYhg0bpjNnztjHTp8+rRdeeEHNmjVL0+IAAACArMhyiH7vvfcUHR2tsmXLqnz58ipfvrwefPBBRUdHa+bMmelRIwAAAJClWF4THRgYqJ07d+r777/XwYMHJUlVqlRRSEhImhcHAAAAZEX39Jxom82m5s2bq3nz5mldDwAAAJDlpXo5xw8//KCqVasqOjo62bYrV66oWrVq2rRpU5oWBwAAAGRFqQ7R06dPV//+/eXr65tsW8GCBfXss8/qnXfeSdPiAAAAgKwo1SF6z549atWqldPtLVq00I4dO9KkKAAAACArS3WIPnfuXIrPh06SJ08eXbhwIU2KAgAAALKyVIfokiVL6tdff3W6fe/evSpevHiaFAUAAABkZakO0W3atNG4ceN08+bNZNtu3LihsLAw/fOf/0zT4gAAAICsKNWPuBs7dqyWL1+uhx56SEOGDFGlSpUkSQcPHtSsWbOUkJCgV199Nd0KBQAAALKKVIdof39//fzzz3ruuec0ZswYGWMk3X5mdMuWLTVr1iz5+/unW6EAAABAVmHpy1bKlCmj1atX69KlSzp69KiMMapYsaIKFy6cXvUBAAAAWU6q10TfqXDhwnr44YdVr169DA/Qs2bNUtmyZeXt7a369etr27ZtLucvWbJElStXlre3t4KCgrR69eoMqhQAAAA51T2F6MzyxRdfaMSIEQoLC9POnTtVs2ZNtWzZUufPn09x/s8//6wePXqoX79+2rVrlzp27KiOHTu6fMoIAAAAcDfZKkS/88476t+/v5566ilVrVpVH3zwgXx8fDR37twU58+YMUOtWrXSiy++qCpVqmjSpEn6xz/+offeey+DKwcAAEBOYmlNdGa6deuWduzYoTFjxtjH3NzcFBISos2bN6e4z+bNmzVixAiHsZYtW2rlypVOzxMbG6vY2Fj76+joaElSXFyc4uLi7uMKsq6k68qp13c/6I1r9Mc5euMa/XGO3jhHb1zLzf3JjGtOsxCdmJio1atXp9uzoi9evKiEhIRkTwDx9/fXwYMHU9wnMjIyxfmRkZFOzzN58mRNnDgx2fjatWvl4+NzD5VnH+Hh4ZldQpZFb1yjP87RG9foj3P0xjl641pu7E9MTEyGn/O+Q/TRo0c1d+5czZ8/XxcuXMj2f/sZM2aMw93r6OhoBQYGqkWLFvL19c3EytJPXFycwsPD1bx5c5df7Z4b0RvX6I9z9MY1+uMcvXGO3riWm/uTtHIgI91TiL5x44aWLFmijz/+WD/99JMaNWqk8ePH6/HHH0/r+uyKFi0qd3d3nTt3zmH83LlzCggISHGfgIAAS/MlycvLS15eXsnGPTw8cvwbMjdc472iN67RH+fojWv0xzl64xy9cS039iczrtfSBwu3b9+uZ599VgEBAZo+fbo6dOggm82m2bNna+DAgen6ZSuenp6qU6eO1q1bZx9LTEzUunXrFBwcnOI+wcHBDvOl2//E4Ww+AAAAkBqpvhNdo0YNRUdHq2fPnvr5559VrVo1SdLo0aPTrbi/GzFihPr27au6deuqXr16mj59uq5fv66nnnpKktSnTx+VLFlSkydPliQNGzZMjRs31r/+9S+1bdtWixcv1i+//KIPP/www2oGAABAzpPqEH3o0CF169ZNTZs2VdWqVdOzJqe6deumCxcuaPz48YqMjFStWrW0Zs0a+x3wU6dOyc3tfzfXGzRooEWLFmns2LF65ZVXVLFiRa1cuVLVq1fPlPoBAACQM6Q6RB8/flzz58/Xc889pxs3bqhHjx7q1auXbDZbetaXzJAhQzRkyJAUt0VERCQb69Kli7p06ZLOVQEAACA3SfWa6JIlS+rVV1/V0aNH9dlnnykyMlINGzZUfHy85s+fr8OHD6dnnQAAAECWcU/fWPjYY49pwYIFOnv2rN577z398MMPqly5smrUqJHW9QEAAABZzn197XfBggU1aNAg/fLLL9q5c6eaNGmSRmUBAAAAWVeqQ/SNGze0atUqXb16Ndm26OhonTp1Sm+//XaaFgcAAABkRakO0R9++KFmzJihAgUKJNvm6+urd999Vx9//HGaFgcAAABkRakO0QsXLtTw4cOdbh8+fLg++eSTtKgJAAAAyNJSHaKPHDmimjVrOt1eo0YNHTlyJE2KAgAAALKyVIfo+Ph4Xbhwwen2CxcuKD4+Pk2KAgAAALKyVIfoatWq6fvvv3e6fe3atfavAgcAAAByslSH6KefflqTJk3S119/nWzbV199pTfeeENPP/10mhYHAAAAZEWp/trvAQMGaOPGjWrfvr0qV66sSpUqSZIOHjyow4cPq2vXrhowYEC6FQoAAABkFZa+bGXBggVavHixKlasqMOHD+vQoUOqVKmSPv/8c33++efpVSMAAACQpaT6TnSSrl27qmvXrulRCwAAAJAtpPpOdGJioqZOnaqGDRvq4Ycf1ujRo3Xjxo30rA0AAADIklIdot944w298soryp8/v0qWLKkZM2Zo8ODB6VkbAAAAkCWlOkR/+umnmj17tr777jutXLlSX331lRYuXKjExMT0rA8AAADIclIdok+dOqU2bdrYX4eEhMhms+nMmTPpUhgAAACQVVn6xkJvb2+HMQ8PD8XFxaV5UQAAAEBWluqncxhjFBoaKi8vL/vYzZs3NXDgQOXLl88+tnz58rStEAAAAMhiUh2i+/btm2zsySefTNNiAAAAgOwg1SF63rx56VkHAAAAkG1Y+sZCAAAAAIRoAAAAwDJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYlG1CdFRUlHr16iVfX18VKlRI/fr107Vr11zOf/7551WpUiXlzZtXpUuX1tChQ3XlypUMrBoAAAA5UbYJ0b169dL+/fsVHh6ur7/+Whs3btSAAQOczj9z5ozOnDmjadOm6ddff9X8+fO1Zs0a9evXLwOrBgAAQE6UJ7MLSI0DBw5ozZo12r59u+rWrStJmjlzptq0aaNp06apRIkSyfapXr26li1bZn9dvnx5vfHGG3ryyScVHx+vPHmyxaUDAAAgC8oWSXLz5s0qVKiQPUBLUkhIiNzc3LR161Y9/vjjqTrOlStX5Ovr6zJAx8bGKjY21v46OjpakhQXF6e4uLh7vIKsLem6cur13Q964xr9cY7euEZ/nKM3ztEb13JzfzLjmrNFiI6MjFSxYsUcxvLkyaMiRYooMjIyVce4ePGiJk2a5HIJiCRNnjxZEydOTDa+du1a+fj4pL7obCg8PDyzS8iy6I1r9Mc5euMa/XGO3jhHb1zLjf2JiYnJ8HNmaogePXq0pk6d6nLOgQMH7vs80dHRatu2rapWraoJEya4nDtmzBiNGDHCYd/AwEC1aNFCvr6+911LVhQXF6fw8HA1b95cHh4emV1OlkJvXKM/ztEb1+iPc/TGOXrjWm7uT9LKgYyUqSF65MiRCg0NdTmnXLlyCggI0Pnz5x3G4+PjFRUVpYCAAJf7X716Va1atVKBAgW0YsWKu76pvLy85OXllWzcw8Mjx78hc8M13it64xr9cY7euEZ/nKM3ztEb13JjfzLjejM1RPv5+cnPz++u84KDg3X58mXt2LFDderUkST98MMPSkxMVP369Z3uFx0drZYtW8rLy0urVq2St7d3mtUOAACA3CtbPOKuSpUqatWqlfr3769t27bpp59+0pAhQ9S9e3f7kzlOnz6typUra9u2bZJuB+gWLVro+vXrmjNnjqKjoxUZGanIyEglJCRk5uUAAAAgm8sWHyyUpIULF2rIkCFq1qyZ3Nzc1LlzZ7377rv27XFxcTp06JB9YfnOnTu1detWSVKFChUcjnXixAmVLVs2w2oHAABAzpJtQnSRIkW0aNEip9vLli0rY4z9dZMmTRxeAwAAAGklWyznAAAAALISQjQAAABgESEaAAAAOUZoaKg6duyY7uchRAMAACBLioiIkM1m0+XLlzO7lGQI0QAAAIBFhGgAAACki6tXr6pXr17Kly+fihcvrn//+99q0qSJhg8fLkn67LPPVLduXRUoUEABAQHq2bOn/VuqT548qaZNm0qSChcuLJvNZv+m66VLlyooKEh58+bVAw88oPbt2yc798SJE+Xn5ydfX18NHDhQt27dkiR9+umneuCBBxQbG+swv2PHjurdu3eqr40QDQAAgHQxYsQI/fTTT1q1apXCw8O1adMm7dy50749Li5OkyZN0p49e7Ry5UqdPHnSHpQDAwO1bNkySdKhQ4d09uxZzZgxQ2fPnlWPHj309NNP68CBA4qIiFC7du0czrtu3Tr7ts8//1zLly/XxIkTJUldunRRQkKCVq1aZZ9//vx5ffPNN3r66adTfW3Z5jnRAAAAyPoSEqRNm6Tjx69q/vxPtHDhIjVr1kySNG/ePPu3TUtyCK3lypXTu+++q4cffljXrl1T/vz5VaRIEUlSsWLFVKhQIUnSsWPHFB8fr06dOqlMmTKSpDJlymjUqFH2Y3l6emru3Lny8fFRtWrV9Nprr+nFF1/UpEmTlDdvXvXs2VPz5s1Tly5dJEkLFixQ6dKl1aRJk1RfJ3eiAQAAkCaWL5fKlpWaNpX69Tuu+Pg4DRtWT8uX395esGBBVapUyT5/x44dateunUqXLq0CBQqocePGkqRTp045PUfNmjXVrFkzBQUFqUuXLvroo4906dKlZHN8fHzsr4ODg3Xt2jX98ccfkqT+/ftr7dq1On36tCRp/vz5Cg0Nlc1mS/W1EqIBAABw35Yvl554QvrzT8fxyMjb40lBOsn169fVsmVL+fr6auHChdq+fbtWrFghSfb1yylxd3dXeHi4vv32W1WtWlUzZ85U3bp1LdVau3Zt1axZU59++ql27Nih/fv325eRpBYhGgAAAPclIUEaNkwy5s7RcpI8JG2XJA0fLkVFXdHhw4clSQcPHtRff/2lKVOmqFGjRqpcubL9Q4VJPD09///xExzGbTabGjZsqIkTJ2rXrl32eUn27NmjGzdu2F9v2bJF+fPnV2BgoH3smWee0fz58zVv3jyFhIQ4bEsNQjQAAADuy6ZNye9ASwUk9ZX0ooxZrz/+2K/HH+8nNzc32Ww2lS5dWp6enpo5c6aOHz+uVatWadKkSQ5HKFOmjGw2m77++mtduHBB165d09atW/Xmm2/ql19+0alTp7R8+XJdvHjRYb9bt26pX79++u2337R69WqFhYVpyJAhcnP7X/Tt2bOn/vzzT3300UeWPlCYhBANAACA+3L2rLMt70gKlvRPSSEqXbqhqlSpIm9vb/n5+Wn+/PlasmSJqlatqilTpmjatGkOe5csWVITJ07U6NGj5e/vryFDhsjX11cbN25UmzZt9NBDD2ns2LF64403HPZr1qyZKlasqEcffVTdunVT+/btNWHCBIc5BQsWVOfOnZU/f/57+oZDns4BAACA+1K8uLMtBSQttL/q2fO6evSYqAEDBkiSevTooR49ejjsYRzXhGjcuHEaN26cw9iaNWscXkdHR+vFF1+UdPtDgkmSHmvnzOnTp9WrVy95eXm5nJcSQjQAAADuS6NGUqlS0unTf18XvUvSQUn15O9/RR988JokqUOHDplQ5f9cunRJERERioiI0OzZs+/pGIRoAAAA3Bd3d2nGjNtP4bDZ/h6kp0k6pOvXPRUTU0ebNm1S0aJFM6nS22rXrq1Lly5p6tSpDo/cs4IQDQAAgPvWqZO0dOntp3T870OGtRUYuEPTp9/enlWcPHnyvo9BiAYAAECa6NRJ6tDh9tM6zp69vVa6UaPbd6pzGkI0AAAA0oy7u2Th27OzLR5xBwAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgUbYJ0VFRUerVq5d8fX1VqFAh9evXT9euXUvVvsYYtW7dWjabTStXrkzfQgEAAJDjZZsQ3atXL+3fv1/h4eH6+uuvtXHjRg0YMCBV+06fPl02my2dKwQAAEBukSezC0iNAwcOaM2aNdq+fbvq1q0rSZo5c6batGmjadOmqUSJEk733b17t/71r3/pl19+UfHixTOqZAAAAORg2SJEb968WYUKFbIHaEkKCQmRm5ubtm7dqscffzzF/WJiYtSzZ0/NmjVLAQEBqTpXbGysYmNj7a+jo6MlSXFxcYqLi7uPq8i6kq4rp17f/aA3rtEf5+iNa/THOXrjHL1xLTf3JzOuOVuE6MjISBUrVsxhLE+ePCpSpIgiIyOd7vfCCy+oQYMG6tChQ6rPNXnyZE2cODHZ+Nq1a+Xj45P6orOh8PDwzC4hy6I3rtEf5+iNa/THOXrjHL1xLTf2JyYmJsPPmakhevTo0Zo6darLOQcOHLinY69atUo//PCDdu3aZWm/MWPGaMSIEfbX0dHRCgwMVIsWLeTr63tPtWR1cXFxCg8PV/PmzeXh4ZHZ5WQp9MY1+uMcvXGN/jhHb5yjN67l5v4krRzISJkaokeOHKnQ0FCXc8qVK6eAgACdP3/eYTw+Pl5RUVFOl2n88MMPOnbsmAoVKuQw3rlzZzVq1EgREREp7ufl5SUvL69k4x4eHjn+DZkbrvFe0RvX6I9z9MY1+uMcvXGO3riWG/uTGdebqSHaz89Pfn5+d50XHBysy5cva8eOHapTp46k2yE5MTFR9evXT3Gf0aNH65lnnnEYCwoK0r///W+1a9fu/osHAABArpUt1kRXqVJFrVq1Uv/+/fXBBx8oLi5OQ4YMUffu3e1P5jh9+rSaNWumTz/9VPXq1VNAQECKd6lLly6tBx98MKMvAQAAADlItnlO9MKFC1W5cmU1a9ZMbdq00SOPPKIPP/zQvj0uLk6HDh3KlIXlAAAAyF2yxZ1oSSpSpIgWLVrkdHvZsmVljHF5jLttBwAAAFIj29yJBgAAALIKQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAMAAAAWEaIBAAAAiwjRAAAAgEWEaAAAAMAiQjQAAABgESEaAAAAsIgQDQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwKNuE6KioKPXq1Uu+vr4qVKiQ+vXrp2vXrt11v82bN+uxxx5Tvnz55Ovrq0cffVQ3btzIgIoBAACQU2WbEN2rVy/t379f4eHh+vrrr7Vx40YNGDDA5T6bN29Wq1at1KJFC23btk3bt2/XkCFD5OaWbS4bAAAAWVCezC4gNQ4cOKA1a9Zo+/btqlu3riRp5syZatOmjaZNm6YSJUqkuN8LL7ygoUOHavTo0faxSpUqZUjNAAAAyLmyRYjevHmzChUqZA/QkhQSEiI3Nzdt3bpVjz/+eLJ9zp8/r61bt6pXr15q0KCBjh07psqVK+uNN97QI4884vRcsbGxio2Ntb+Ojo6WJMXFxSkuLi4NryrrSLqunHp994PeuEZ/nKM3rtEf5+iNc/TGtdzcn8y45mwRoiMjI1WsWDGHsTx58qhIkSKKjIxMcZ/jx49LkiZMmKBp06apVq1a+vTTT9WsWTP9+uuvqlixYor7TZ48WRMnTkw2vnbtWvn4+NznlWRt4eHhmV1ClkVvXKM/ztEb1+iPc/TGOXrjWm7sT0xMTIafM1ND9OjRozV16lSXcw4cOHBPx05MTJQkPfvss3rqqackSbVr19a6des0d+5cTZ48OcX9xowZoxEjRthfR0dHKzAwUC1atJCvr+891ZLVxcXFKTw8XM2bN5eHh0dml5Ol0BvX6I9z9MY1+uMcvXGO3riWm/uTtHIgI2VqiB45cqRCQ0NdzilXrpwCAgJ0/vx5h/H4+HhFRUUpICAgxf2KFy8uSapatarDeJUqVXTq1Cmn5/Py8pKXl1eycQ8Pjxz/hswN13iv6I1r9Mc5euMa/XGO3jhHb1zLjf3JjOvN1BDt5+cnPz+/u84LDg7W5cuXtWPHDtWpU0eS9MMPPygxMVH169dPcZ+yZcuqRIkSOnTokMP44cOH1bp16/svHgAAALlWtnjWW5UqVdSqVSv1799f27Zt008//aQhQ4aoe/fu9idznD59WpUrV9a2bdskSTabTS+++KLeffddLV26VEePHtW4ceN08OBB9evXLzMvJ1WaNGmi4cOHZ3YZAAAASEG2+GChJC1cuFBDhgxRs2bN5Obmps6dO+vdd9+1b4+Li9OhQ4ccFpYPHz5cN2/e1AsvvKCoqCjVrFlT4eHhKl++fGZcAgAAAHKIbHEnWpKKFCmiRYsW6erVq7py5Yrmzp2r/Pnz27eXLVtWxhg1adLEYb/Ro0frjz/+0PXr1/Xzzz+7fLxdVhEaGqoNGzZoxowZstlsstlsOnnypDZs2KB69erJy8tLxYsX1+jRoxUfH2/fr0mTJnr++ec1fPhwFS5cWP7+/vroo490/fp1PfXUUypQoIAqVKigb7/9NhOvDgAAIPvLNiE6N5kxY4aCg4PVv39/nT17VmfPnpWHh4fatGmjhx9+WHv27NH777+vOXPm6PXXX3fY95NPPlHRokW1bds2Pf/883ruuefUpUsXNWjQQDt37lSLFi3Uu3fvTHkUDAAAQE5BiM6CChYsKE9PT/n4+CggIEABAQGaPXu2AgMD9d5776ly5crq2LGjJk6cqH/961/2x/lJUs2aNTV27FhVrFhRY8aMkbe3t4oWLar+/furYsWKGj9+vP766y/t3bs3E68QAAAge8s2a6Jzg4QEadMm6exZ6fJlyZj/bTtw4ICCg4Nls9nsYw0bNtS1a9f0559/qnTp0pKkGjVq2Le7u7vrgQceUFBQkH3M399fkpI9MhAAAACpR4jOIpYvl4YNk/78839jx45JjRtLnTql/jh/f06izWZzGEsK4XfevQYAAIA1LOfIApYvl554wjFAS566di1BTzxxe3uVKlW0efNmmTtuT//0008qUKCASpUqleE1AwAA5GaE6EyWkHD7DvSdSzduKytpq4w5qeefv6hnnx2kP/74Q88//7wOHjyoL7/8UmFhYRoxYoTc3PhtBAAAyEikr0y2adPf70AnGSXJXVJVnTnjp59/jtPq1au1bds21axZUwMHDlS/fv00duzYjC0YAAAArInObGfPOtvykKTN9lfGSI0bl7V/I2NKIiIiko2dPHky2ZhJftsbAAAAFnAnOpMVL5628wAAAJD+CNGZrFEjqVQp6Y4n1zmw2aTAwNvzAAAAkDUQojOZu7s0Y8btX/89SCe9nj799jwAAABkDYToLKBTJ2npUqlkScfxUqVuj1t5TjQAAADSHx8szCI6dZI6dPjfNxYWL357CQd3oAEAALIeQnQW4u4uNWmS2VUAAADgbljOAQAAAFhEiAYAAAAsIkQDAAAAFhGiAQAAAIsI0QAAAIBFhGgAAADAIkI0AAAAYBEhGgAAALCIEA0AAABYRIgGAAAALCJEAwAAABYRogEAAACLCNEAAACARXkyu4CszhgjSYqOjs7kStJPXFycYmJiFB0dLQ8Pj8wuJ0uhN67RH+fojWv0xzl64xy9cS039ycppyXltoxAiL6Lq1evSpICAwMzuRIAAAC4cvXqVRUsWDBDzmUzGRnZs6HExESdOXNGBQoUkM1my+xy0kV0dLQCAwP1xx9/yNfXN7PLyVLojWv0xzl64xr9cY7eOEdvXMvN/THG6OrVqypRooTc3DJmtTJ3ou/Czc1NpUqVyuwyMoSvr2+u+z9datEb1+iPc/TGNfrjHL1xjt64llv7k1F3oJPwwUIAAADAIkI0AAAAYBEhGvLy8lJYWJi8vLwyu5Qsh964Rn+cozeu0R/n6I1z9MY1+pOx+GAhAAAAYBF3ogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIToXiIqKUq9eveTr66tChQqpX79+unbtmtP5J0+elM1mS/FnyZIl9nkpbV+8eHFGXFKastofSWrSpEmyax84cKDDnFOnTqlt27by8fFRsWLF9OKLLyo+Pj49LyXNWe1NVFSUnn/+eVWqVEl58+ZV6dKlNXToUF25csVhXnZ978yaNUtly5aVt7e36tevr23btrmcv2TJElWuXFne3t4KCgrS6tWrHbYbYzR+/HgVL15cefPmVUhIiI4cOZKel5BurPTmo48+UqNGjVS4cGEVLlxYISEhyeaHhoYme4+0atUqvS8j3Vjpz/z585Ndu7e3t8Oc3PreSenPXpvNprZt29rn5JT3zsaNG9WuXTuVKFFCNptNK1euvOs+ERER+sc//iEvLy9VqFBB8+fPTzbH6p9jcMEgx2vVqpWpWbOm2bJli9m0aZOpUKGC6dGjh9P58fHx5uzZsw4/EydONPnz5zdXr161z5Nk5s2b5zDvxo0bGXFJacpqf4wxpnHjxqZ///4O137lyhX79vj4eFO9enUTEhJidu3aZVavXm2KFi1qxowZk96Xk6as9mbfvn2mU6dOZtWqVebo0aNm3bp1pmLFiqZz584O87Lje2fx4sXG09PTzJ071+zfv9/079/fFCpUyJw7dy7F+T/99JNxd3c3b731lvntt9/M2LFjjYeHh9m3b599zpQpU0zBggXNypUrzZ49e0z79u3Ngw8+mOV78XdWe9OzZ08za9Yss2vXLnPgwAETGhpqChYsaP7880/7nL59+5pWrVo5vEeioqIy6pLSlNX+zJs3z/j6+jpce2RkpMOc3Pre+euvvxz68uuvvxp3d3czb948+5yc8t5ZvXq1efXVV83y5cuNJLNixQqX848fP258fHzMiBEjzG+//WZmzpxp3N3dzZo1a+xzrPYbrhGic7jffvvNSDLbt2+3j3377bfGZrOZ06dPp/o4tWrVMk8//bTDWGr+T53V3Wt/GjdubIYNG+Z0++rVq42bm5vDf/jef/994+vra2JjY9Ok9vSWVu+d//73v8bT09PExcXZx7Lje6devXpm8ODB9tcJCQmmRIkSZvLkySnO79q1q2nbtq3DWP369c2zzz5rjDEmMTHRBAQEmLffftu+/fLly8bLy8t8/vnn6XAF6cdqb/4uPj7eFChQwHzyySf2sb59+5oOHTqkdamZwmp/5s2bZwoWLOj0eLx3/uff//63KVCggLl27Zp9LCe9d5Kk5s/Ml156yVSrVs1hrFu3bqZly5b21/fbbzhiOUcOt3nzZhUqVEh169a1j4WEhMjNzU1bt25N1TF27Nih3bt3q1+/fsm2DR48WEWLFlW9evU0d+5cmWz22PH76c/ChQtVtGhRVa9eXWPGjFFMTIzDcYOCguTv728fa9mypaKjo7V///60v5B0kBbvHUm6cuWKfH19lSdPHofx7PTeuXXrlnbs2KGQkBD7mJubm0JCQrR58+YU99m8ebPDfOn2eyBp/okTJxQZGekwp2DBgqpfv77TY2ZF99Kbv4uJiVFcXJyKFCniMB4REaFixYqpUqVKeu655/TXX3+lae0Z4V77c+3aNZUpU0aBgYHq0KGDw58bvHf+Z86cOerevbvy5cvnMJ4T3jtW3e3PnLToNxzlufsUZGeRkZEqVqyYw1iePHlUpEgRRUZGpuoYc+bMUZUqVdSgQQOH8ddee02PPfaYfHx8tHbtWg0aNEjXrl3T0KFD06z+9Hav/enZs6fKlCmjEiVKaO/evXr55Zd16NAhLV++3H7cOwO0JPvr1PY9s6XFe+fixYuaNGmSBgwY4DCe3d47Fy9eVEJCQoq/pwcPHkxxH2fvgaTeJf2vqznZwb305u9efvlllShRwuE/7q1atVKnTp304IMP6tixY3rllVfUunVrbd68We7u7ml6DenpXvpTqVIlzZ07VzVq1NCVK1c0bdo0NWjQQPv371epUqV47/x/27Zt06+//qo5c+Y4jOeU945Vzv7MiY6O1o0bN3Tp0qX7/v8qHBGis6nRo0dr6tSpLuccOHDgvs9z48YNLVq0SOPGjUu27c6x2rVr6/r163r77bezRBBK7/7cGQqDgoJUvHhxNWvWTMeOHVP58uXv+bgZIaPeO9HR0Wrbtq2qVq2qCRMmOGzLyu8dZKwpU6Zo8eLFioiIcPjwXPfu3e2/DgoKUo0aNVS+fHlFRESoWbNmmVFqhgkODlZwcLD9dYMGDVSlShX95z//0aRJkzKxsqxlzpw5CgoKUr169RzGc/N7BxmLEJ1NjRw5UqGhoS7nlCtXTgEBATp//rzDeHx8vKKiohQQEHDX8yxdulQxMTHq06fPXefWr19fkyZNUmxsrLy8vO46Pz1lVH+S1K9fX5J09OhRlS9fXgEBAck+8Xzu3DlJsnTc9JARvbl69apatWqlAgUKaMWKFfLw8HA5Pyu9d1JStGhRubu7238Pk5w7d85pLwICAlzOT/rfc+fOqXjx4g5zatWqlYbVp6976U2SadOmacqUKfr+++9Vo0YNl3PLlSunokWL6ujRo9kqCN1Pf5J4eHiodu3aOnr0qCTeO5J0/fp1LV68WK+99tpdz5Nd3ztWOfszx9fXV3nz5pW7u/t9vxfhiDXR2ZSfn58qV67s8sfT01PBwcG6fPmyduzYYd/3hx9+UGJioj34uTJnzhy1b99efn5+d527e/duFS5cOEuEoIzqT5Ldu3dLkv0/aMHBwdq3b59DCA0PD5evr6+qVq2aNhd5j9K7N9HR0WrRooU8PT21atWqZI/mSklWeu+kxNPTU3Xq1NG6devsY4mJiVq3bp3DHcM7BQcHO8yXbr8HkuY/+OCDCggIcJgTHR2trVu3Oj1mVnQvvZGkt956S5MmTdKaNWsc1t078+eff+qvv/5yCI3Zwb32504JCQnat2+f/dpz+3tHuv34yNjYWD355JN3PU92fe9Ydbc/c9LivYi/yexPNiL9tWrVytSuXdts3brV/Pjjj6ZixYoOjyn7888/TaVKlczWrVsd9jty5Iix2Wzm22+/TXbMVatWmY8++sjs27fPHDlyxMyePdv4+PiY8ePHp/v1pDWr/Tl69Kh57bXXzC+//GJOnDhhvvzyS1OuXDnz6KOP2vdJesRdixYtzO7du82aNWuMn59ftnzEnZXeXLlyxdSvX98EBQWZo0ePOjxiKj4+3hiTfd87ixcvNl5eXmb+/Pnmt99+MwMGDDCFChWyP4Gld+/eZvTo0fb5P/30k8mTJ4+ZNm2aOXDggAkLC0vxEXeFChUyX375pdm7d6/p0KFDtn1MmZXeTJkyxXh6epqlS5c6vEeSHqF59epVM2rUKLN582Zz4sQJ8/3335t//OMfpmLFiubmzZuZco33w2p/Jk6caL777jtz7Ngxs2PHDtO9e3fj7e1t9u/fb5+TW987SR555BHTrVu3ZOM56b1z9epVs2vXLrNr1y4jybzzzjtm165d5vfffzfGGDN69GjTu3dv+/ykR9y9+OKL5sCBA2bWrFkpPuLOVb9hDSE6F/jrr79Mjx49TP78+Y2vr6956qmnHJ73fOLECSPJrF+/3mG/MWPGmMDAQJOQkJDsmN9++62pVauWyZ8/v8mXL5+pWbOm+eCDD1Kcm9VZ7c+pU6fMo48+aooUKWK8vLxMhQoVzIsvvujwnGhjjDl58qRp3bq1yZs3rylatKgZOXKkw2PesgOrvVm/fr2RlOLPiRMnjDHZ+70zc+ZMU7p0aePp6Wnq1atntmzZYt/WuHFj07dvX4f5//3vf81DDz1kPD09TbVq1cw333zjsD0xMdGMGzfO+Pv7Gy8vL9OsWTNz6NChjLiUNGelN2XKlEnxPRIWFmaMMSYmJsa0aNHC+Pn5GQ8PD1OmTBnTv3//bP0feiv9GT58uH2uv7+/adOmjdm5c6fD8XLre8cYYw4ePGgkmbVr1yY7Vk567zj78zSpH3379jWNGzdOtk+tWrWMp6enKVeunMPzs5O46jessRmThZ8rBQAAAGRBrIkGAAAALCJEAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACwiRAPI1UJDQ2Wz2WSz2eTp6akKFSrotddeU3x8vH2OMUYffvih6tevr/z586tQoUKqW7eupk+frpiYGIfj/fnnn/L09FT16tVTXUNkZKSef/55lStXTl5eXgoMDFS7du20bt26NLvOnCA0NFQdO3a867yNGzeqXbt2KlGihGw2m1auXJnutQHIfQjRAHK9Vq1a6ezZszpy5IhGjhypCRMm6O2337Zv7927t4YPH64OHTpo/fr12r17t8aNG6cvv/xSa9eudTjW/Pnz1bVrV0VHR2vr1q13PffJkydVp04d/fDDD3r77be1b98+rVmzRk2bNtXgwYPT/Fpzg+vXr6tmzZqaNWtWZpcCICczAJCL9e3b13To0MFhrHnz5ub//u//jDHGfPHFF0aSWblyZbJ9ExMTzeXLlx1elytXzqxZs8a8/PLLpn///nc9f+vWrU3JkiXNtWvXkm27dOmS/de///67ad++vcmXL58pUKCA6dKli4mMjLRvDwsLMzVr1jRz5swxgYGBJl++fOa5554z8fHxZurUqcbf39/4+fmZ119/3eEckszs2bNNq1atjLe3t3nwwQfNkiVLHObs3bvXNG3a1Hh7e5siRYqY/v37m6tXrybr4dtvv20CAgJMkSJFzKBBg8ytW7fsc27evGlGjhxpSpQoYXx8fEy9evXM+vXr7dvnzZtnChYsaNasWWMqV65s8uXLZ1q2bGnOnDljvz5JDj937u+MJLNixYq7zgMAq7gTDQB/kzdvXt26dUuStHDhQlWqVEkdOnRINs9ms6lgwYL21+vXr1dMTIxCQkL05JNPavHixbp+/brT80RFRWnNmjUaPHiw8uXLl2x7oUKFJEmJiYnq0KGDoqKitGHDBoWHh+v48ePq1q2bw/xjx47p22+/1Zo1a/T5559rzpw5atu2rf78809t2LBBU6dO1dixY5PdIR83bpw6d+6sPXv2qFevXurevbsOHDgg6fZd3ZYtW6pw4cLavn27lixZou+//15DhgxxOMb69et17NgxrV+/Xp988onmz5+v+fPn27cPGTJEmzdv1uLFi7V371516dJFrVq10pEjR+xzYmJiNG3aNH322WfauHGjTp06pVGjRkmSRo0apa5du9r/1eDs2bNq0KCB094CQLrL7BQPAJnpzjvRiYmJJjw83Hh5eZlRo0YZY4ypUqWKad++faqO1bNnTzN8+HD765o1a5p58+Y5nb9161YjySxfvtzlcdeuXWvc3d3NqVOn7GP79+83ksy2bduMMbfv1Pr4+Jjo6Gj7nJYtW5qyZcuahIQE+1ilSpXM5MmT7a8lmYEDBzqcr379+ua5554zxhjz4YcfmsKFCzvcKf/mm2+Mm5ub/U543759TZkyZUx8fLx9TpcuXUy3bt2MMbfvoru7u5vTp087nKdZs2ZmzJgxxpjbd6IlmaNHj9q3z5o1y/j7+9tfp/SvBncj7kQDSCd5MjXBA0AW8PXXXyt//vyKi4tTYmKievbsqQkTJki6/aHC1Lh8+bKWL1+uH3/80T725JNPas6cOQoNDU1xn9Qe+8CBAwoMDFRgYKB9rGrVqipUqJAOHDighx9+WJJUtmxZFShQwD7H399f7u7ucnNzcxg7f/68w/GDg4OTvd69e7f93DVr1nS4U96wYUMlJibq0KFD8vf3lyRVq1ZN7u7u9jnFixfXvn37JEn79u1TQkKCHnroIYfzxMbG6oEHHrC/9vHxUfny5R2O8fdaASCrIEQDyPWaNm2q999/X56enipRooTy5PnfH40PPfSQDh48eNdjLFq0SDdv3lT9+vXtY8YYJSYm6vDhw8kCpCRVrFhRNpstVcdPDQ8PD4fXNpstxbHExMQ0Od/dzp10nmvXrsnd3V07duxwCNqSlD9/fpfHSO1fNAAgo7EmGkCuly9fPlWoUEGlS5d2CNCS1LNnTx0+fFhffvllsv2MMbpy5Yokac6cORo5cqR2795t/9mzZ48aNWqkuXPnpnjeIkWKqGXLlpo1a1aKa6cvX74sSapSpYr++OMP/fHHH/Ztv/32my5fvqyqVave62XbbdmyJdnrKlWq2M+9Z88eh/p++uknubm5qVKlSqk6fu3atZWQkKDz58+rQoUKDj8BAQGprtPT01MJCQmpng8A6YkQDQAudO3aVd26dVOPHj305ptv6pdfftHvv/+ur7/+WiEhIfZH3u3cuVPPPPOMqlev7vDTo0cPffLJJw7Pnb7TrFmzlJCQoHr16mnZsmU6cuSIDhw4oHfffde+zCIkJERBQUHq1auXdu7cqW3btqlPnz5q3Lix6tate9/XuGTJEs2dO1eHDx9WWFiYtm3bZv/gYK9eveTt7a2+ffvq119/1fr16/X888+rd+/e9qUcd/PQQw+pV69e6tOnj5YvX64TJ05o27Ztmjx5sr755ptU11m2bFnt3btXhw4d0sWLFxUXF5fivGvXrtn/IiNJJ06c0O7du3Xq1KlUnwsA7oYQDQAu2Gw2LVq0SO+8845Wrlypxo0bq0aNGpowYYI6dOigli1bas6cOapataoqV66cbP/HH39c58+f1+rVq1M8frly5bRz5041bdpUI0eOVPXq1dW8eXOtW7dO77//vr2GL7/8UoULF9ajjz6qkJAQlStXTl988UWaXOPEiRO1ePFi1ahRQ59++qk+//xz+x1uHx8ffffdd4qKitLDDz+sJ554Qs2aNdN7771n6Rzz5s1Tnz59NHLkSFWqVEkdO3bU9u3bVbp06VQfo3///qpUqZLq1q0rPz8//fTTTynO++WXX1S7dm3Vrl1bkjRixAjVrl1b48ePt1QzALhiMyw4A4Bcy2azacWKFan6JkAAwP9wJxoAAACwiBANAAAAWMQj7gAgF2NFHwDcG+5EAwAAABYRogEAAACLCNEAAACARYRoAAAAwCJCNAAAAGARIRoAAACwiBANAAAAWESIBgAAACz6fwh3MDHDqwOjAAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the word vectors (optional)\n",
        "# You can use a dimensionality reduction technique like PCA or t-SNE to visualize the vectors\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "gatsby_key_characters = ['gatsby', 'daisy', 'tom']\n",
        "\n",
        "# Get the vectors for the key characters\n",
        "vectors = [skipgram_gatsby_model.wv[char] for char in gatsby_key_characters if char in skipgram_gatsby_model.wv]\n",
        "\n",
        "# Perform PCA to reduce dimensions to 2D for visualization\n",
        "pca = PCA(n_components=2)\n",
        "reduced_vectors = pca.fit_transform(vectors)\n",
        "\n",
        "# Plot the vectors\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1], c='blue')\n",
        "for i, char in enumerate(gatsby_key_characters):\n",
        "    if char in skipgram_gatsby_model.wv:\n",
        "        plt.annotate(char, (reduced_vectors[i, 0], reduced_vectors[i, 1]))\n",
        "plt.title('2D PCA of Character Embeddings')\n",
        "plt.xlabel('PCA Component 1')\n",
        "plt.ylabel('PCA Component 2')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOKI0Rh0DNXt"
      },
      "outputs": [],
      "source": [
        "# Get Similaries using The Adventures of Huckleberry Finn (Optional)\n",
        "\n",
        "\n",
        "# Define key characters\n",
        "huck_key_characters = ['huck', 'jim', 'pap', 'duke']\n",
        "\n",
        "\n",
        "# Investigate the relationships between the characters\n",
        "\n",
        "# Your code here\n",
        "\n",
        "# Print the cosine similarities of the relationships in Adventures iof Huckleberry Finn\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86S07P5ICIVg"
      },
      "source": [
        "## Parts of Speech Tagging (POS)\n",
        "\n",
        "In the code cells below, we shall perform simple POS.\n",
        "In this section, we shall use sentences from 'Adventures of Huckleberry Finn' and 'The Adventures of Sherlock Holmes'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y86YfUTVE_I5"
      },
      "outputs": [],
      "source": [
        "from spacy import displacy # import spaCy's visualizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2hNp2Mvh8dfm",
        "outputId": "dd710660-d8c9-4ef7-87d1-2bba94113b49"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'You': ('PRON', 'pronoun'),\n",
              " 'do': ('AUX', 'auxiliary'),\n",
              " 'n’t': ('PART', 'particle'),\n",
              " 'know': ('VERB', 'verb'),\n",
              " 'about': ('ADP', 'adposition'),\n",
              " 'me': ('PRON', 'pronoun'),\n",
              " 'without': ('SCONJ', 'subordinating conjunction'),\n",
              " 'you': ('PRON', 'pronoun'),\n",
              " 'have': ('AUX', 'auxiliary'),\n",
              " 'read': ('VERB', 'verb'),\n",
              " 'a': ('DET', 'determiner'),\n",
              " 'book': ('NOUN', 'noun'),\n",
              " 'by': ('ADP', 'adposition'),\n",
              " 'the': ('DET', 'determiner'),\n",
              " 'name': ('NOUN', 'noun'),\n",
              " 'of': ('ADP', 'adposition'),\n",
              " 'The': ('DET', 'determiner'),\n",
              " ' ': ('SPACE', 'space'),\n",
              " 'Adventures': ('PROPN', 'proper noun'),\n",
              " 'Tom': ('PROPN', 'proper noun'),\n",
              " 'Sawyer': ('PROPN', 'proper noun'),\n",
              " ';': ('PUNCT', 'punctuation'),\n",
              " 'but': ('CCONJ', 'coordinating conjunction'),\n",
              " 'that': ('PRON', 'pronoun'),\n",
              " 'ai': ('VERB', 'verb'),\n",
              " 'no': ('ADV', 'adverb'),\n",
              " 'matter': ('NOUN', 'noun'),\n",
              " '.': ('PUNCT', 'punctuation'),\n",
              " 'That': ('PRON', 'pronoun'),\n",
              " 'was': ('AUX', 'auxiliary'),\n",
              " 'made': ('VERB', 'verb'),\n",
              " 'Mr.': ('PROPN', 'proper noun'),\n",
              " 'Mark': ('PROPN', 'proper noun'),\n",
              " 'Twain': ('PROPN', 'proper noun'),\n",
              " ',': ('PUNCT', 'punctuation'),\n",
              " 'and': ('CCONJ', 'coordinating conjunction'),\n",
              " 'he': ('PRON', 'pronoun'),\n",
              " 'told': ('VERB', 'verb'),\n",
              " 'truth': ('NOUN', 'noun'),\n",
              " 'mainly': ('ADV', 'adverb'),\n",
              " 'There': ('PRON', 'pronoun'),\n",
              " 'things': ('NOUN', 'noun'),\n",
              " 'which': ('PRON', 'pronoun'),\n",
              " 'stretched': ('VERB', 'verb'),\n",
              " 'is': ('AUX', 'auxiliary'),\n",
              " 'nothing': ('PRON', 'pronoun'),\n",
              " 'I': ('PRON', 'pronoun'),\n",
              " 'never': ('ADV', 'adverb'),\n",
              " 'seen': ('VERB', 'verb'),\n",
              " 'anybody': ('PRON', 'pronoun'),\n",
              " 'lied': ('VERB', 'verb'),\n",
              " 'one': ('NUM', 'numeral'),\n",
              " 'time': ('NOUN', 'noun'),\n",
              " 'or': ('CCONJ', 'coordinating conjunction'),\n",
              " 'another': ('PRON', 'pronoun'),\n",
              " 'it': ('PRON', 'pronoun'),\n",
              " 'Aunt': ('PROPN', 'proper noun'),\n",
              " 'Polly': ('PROPN', 'proper noun'),\n",
              " 'widow': ('NOUN', 'noun'),\n",
              " 'maybe': ('ADV', 'adverb'),\n",
              " 'Mary': ('PROPN', 'proper noun')}"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the first 5 sentences of Huckleberry Finn as the corpus\n",
        "h_berry_corpus = h_berry_sents_spacy[:5]\n",
        "\n",
        "# Join the sentences into a single text for SpaCy processing\n",
        "text = ' '.join(h_berry_corpus)\n",
        "\n",
        "# Process the text with SpaCy\n",
        "h_berry_doc = nlp(text)\n",
        "\n",
        "# Initialize an empty dictionary to store the POS tags\n",
        "h_berry_pos_tags = {}\n",
        "\n",
        "# Print POS tags for each token and store them in the dictionary\n",
        "for token in h_berry_doc:\n",
        "    h_berry_pos_tags[token.text] = (token.pos_,spacy.explain(token.pos_))\n",
        "\n",
        "h_berry_pos_tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 440
        },
        "id": "YplOH_ipD3wk",
        "outputId": "48196f86-9b8c-495d-b397-df9ad5df6f1c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"d0fd0257a1394ff19ff672fd1b79b5e1-0\" class=\"displacy\" width=\"2150\" height=\"399.5\" direction=\"ltr\" style=\"max-width: none; height: 399.5px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">You</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">do</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">n’t</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">know</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">about</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">me</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">without</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1275\">you</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1275\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1450\">have</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1450\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1625\">read</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1625\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1800\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1800\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"309.5\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1975\">book</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1975\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-0\" stroke-width=\"2px\" d=\"M70,264.5 C70,2.0 575.0,2.0 575.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,266.5 L62,254.5 78,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-1\" stroke-width=\"2px\" d=\"M245,264.5 C245,89.5 570.0,89.5 570.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,266.5 L237,254.5 253,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-2\" stroke-width=\"2px\" d=\"M420,264.5 C420,177.0 565.0,177.0 565.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">neg</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M420,266.5 L412,254.5 428,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-3\" stroke-width=\"2px\" d=\"M595,264.5 C595,177.0 740.0,177.0 740.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M740.0,266.5 L748.0,254.5 732.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-4\" stroke-width=\"2px\" d=\"M770,264.5 C770,177.0 915.0,177.0 915.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M915.0,266.5 L923.0,254.5 907.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-5\" stroke-width=\"2px\" d=\"M595,264.5 C595,89.5 1095.0,89.5 1095.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1095.0,266.5 L1103.0,254.5 1087.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-6\" stroke-width=\"2px\" d=\"M1295,264.5 C1295,89.5 1620.0,89.5 1620.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1295,266.5 L1287,254.5 1303,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-7\" stroke-width=\"2px\" d=\"M1470,264.5 C1470,177.0 1615.0,177.0 1615.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1470,266.5 L1462,254.5 1478,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-8\" stroke-width=\"2px\" d=\"M595,264.5 C595,2.0 1625.0,2.0 1625.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">ccomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1625.0,266.5 L1633.0,254.5 1617.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-9\" stroke-width=\"2px\" d=\"M1820,264.5 C1820,177.0 1965.0,177.0 1965.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1820,266.5 L1812,254.5 1828,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-10\" stroke-width=\"2px\" d=\"M1645,264.5 C1645,89.5 1970.0,89.5 1970.0,264.5\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-d0fd0257a1394ff19ff672fd1b79b5e1-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1970.0,266.5 L1978.0,254.5 1962.0,254.5\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the parts of speech of the first 12 words in our h_berry doc\n",
        "displacy.render(h_berry_doc[:12], style='dep', jupyter=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UV61Go32IrC7"
      },
      "source": [
        "### POS examples with The Adentures of Sherlock Holmes (Optional)\n",
        "\n",
        "This is for practice on POS that we have just done above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_BSZjIiKFP9d"
      },
      "outputs": [],
      "source": [
        "# Get the first 5 sentences of Sherlock Holmes as the corpus\n",
        "\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGe-AbceH2wA"
      },
      "outputs": [],
      "source": [
        "# Visualize the parts of speech of the first 14 words in our sherlock_holmes doc\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKvgRNdRK_3a"
      },
      "source": [
        "## Named Entity Recognition (NER)\n",
        "NER is information extraction that involves identifying and classifying named entities mentioned in unstructured text into predefined categories such as the names of people, organizations, locations, dates, and other entities\n",
        "In the code cells below, we shall perform NER using sentences from Adventures Huckleberry Finn and The Adventures of Sherlock Holmes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg0FbatnIVWK",
        "outputId": "08e8ab04-90b6-4e8c-9bcd-5aa93aa632be"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tom Sawyer: PERSON\n",
            "Mark Twain: PERSON\n",
            "Aunt: PERSON\n",
            "Mary: PERSON\n"
          ]
        }
      ],
      "source": [
        "# NER tags of the first 5 sentences of Adventures of Huckleberry Finn\n",
        "\n",
        "# Print NER tags for each token and store them in the dictionary\n",
        "for ent in h_berry_doc.ents:\n",
        "  print(f\"{ent.text}: {ent.label_}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "fUqHhWg4OHq6",
        "outputId": "943b4ba6-4e54-43e2-9be2-63501ef5bf8c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">You don’t know about me without you have read a book by the name of The  Adventures of \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Tom Sawyer\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "; but that ain’t no matter. That book was made  by Mr. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mark Twain\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", and he told the truth, mainly. There was things  which he stretched, but mainly he told the truth. That is nothing. I  never seen anybody but lied one time or another, without it was \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Aunt\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              "  Polly, or the widow, or maybe \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Mary\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Visualize the entities of Adventures of Huckleberry Finn\n",
        "displacy.render(h_berry_doc, style='ent', jupyter=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUJkPOs-OPp0"
      },
      "outputs": [],
      "source": [
        "# Get the NER tags of the first 5 sentences of The Adventures of Sherlock Holmes\n",
        "\n",
        "s_holmes_ner_tags = {}\n",
        "\n",
        "# Your code here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1wYAXttOsQP"
      },
      "outputs": [],
      "source": [
        "# Visualize the entities of The Adventures of Sherlock Holmes\n",
        "\n",
        "# Your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}